@article{chari_diverse_2020,
	title={Diverse {R-PPG}: Camera-Based Heart Rate Estimation for Diverse Subject Skin-Tones and Scenes},
	author={Chari, Pradyumna and Kabra, Krish and Karinca, Doruk and Lahiri, Soumyarup and Srivastava, Diplav and Kulkarni, Kimaya and Chen, Tianyuan and Cannesson, Maxime and Jalilian, Laleh and Kadambi, Achuta},
	journal={arXiv preprint arXiv:2010.12769},
	year={2020}
}

@article{blanik_remote_2016,
	title = {Remote vital parameter monitoring in neonatology – robust, unobtrusive heart rate detection in a realistic clinical scenario},
	volume = {61},
	issn = {1862-278X, 0013-5585},
	url = {https://www.degruyter.com/view/journals/bmte/61/6/article-p631.xml},
	doi = {10.1515/bmt-2016-0025},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="abstractTitle text-title my-1" id="d673e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Vital parameter monitoring of term and preterm infants during incubator care with self-adhesive electrodes or sensors directly positioned on the skin [e.g. photoplethysmography (PPG) for oxygen saturation or electrocardiography (ECG)] is an essential part of daily routine care in neonatal intensive care units. For various reasons, this kind of monitoring contains a lot of stress for the infants. Therefore, there is a need to measure vital parameters (for instance respiration, temperature, pulse, oxygen saturation) without mechanical or conductive contact. As a non-contact method of monitoring, we present an adapted version of camera-based photoplethysmography imaging (PPGI) according to neonatal requirements. Similar to classic PPG, the PPGI camera detects small temporal changes in the term and preterm infant’s skin brightness due to the cardiovascular rhythm of dermal blood perfusion. We involved 10 preterm infants in a feasibility study [five males and five females; mean gestational age: 26 weeks (24–28 weeks); mean biological age: 35 days (8–41 days); mean weight at the time of investigation: 960 g (670–1290 g)]. The PPGI camera was placed directly above the incubators with the infant inside illuminated by an infrared light emitting diode (LED) array (850 nm). From each preterm infant, 5-min video sequences were recorded and analyzed post hoc. As the measurement scenario was kept as realistic as possible, the infants were not constrained in their movements in front of the camera. Movement intensities were assigned into five classes (1: no visible motion to 5: heavy struggling). PPGI was found to be significantly sensitive to movement artifacts. However, for movement classes 1–4, changes in blood perfusion according to the heart rate (HR) were recovered successfully (Pearson correlation: r=0.9759; r=0.765 if class 5 is included). The study was approved by the Ethics Committee of the Universal Hospital of the RWTH Aachen University, Aachen, Germany (EK 254/13).{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	language = {en},
	number = {6},
	urldate = {2020-10-20},
	journal = {Biomedical Engineering / Biomedizinische Technik},
	author = {Blanik, Nikolai and Heimann, Konrad and Pereira, Carina and Paul, Michael and Blazek, Vladimir and Venema, Boudewijn and Orlikowsky, Thorsten and Leonhardt, Steffen},
	month = dec,
	year = {2016},
	note = {Publisher: De Gruyter
Section: Biomedical Engineering / Biomedizinische Technik},
	pages = {631--643},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\CLW5T8NG\\article-p631.html:text/html}
}

@inproceedings{moreno_remote_2016,
	title = {Remote monitoring system of vital signs for triage and detection of anomalous patient states in the emergency room},
	doi = {10.1109/STSIVA.2016.7743353},
	abstract = {The monitoring of patient's vital signs is a crucial part of triage in the emergency room in order to determine the severity of their state. This paper describes the development of a remote and constant monitoring system of vital signs in the emergency room as support to the patient triage process. The system keeps track of the patient's state for the proper treatment of emergency situations. The monitoring is accomplished through a bracelet that allows to measure body temperature, pulse and respiratory rate by processing the signals generated by a temperature sensor and a photoplethysmograph. Signals are transmitted in real time to a computer system that enables to visualize vital sign information and generates alerts if an anomalous situation is detected.},
	booktitle = {2016 {XXI} {Symposium} on {Signal} {Processing}, {Images} and {Artificial} {Vision} ({STSIVA})},
	author = {Moreno, S. and Quintero, A. and Ochoa, C. and Bonfante, M. and Villareal, R. and Pestana, J.},
	month = aug,
	year = {2016},
	note = {ISSN: 2329-6259},
	keywords = {Biomedical monitoring, photoplethysmography, medical image processing, patient monitoring, vital signs, respiratory rate, telemedicine, anomalous patient states, Band-pass filters, body temperature, emergency room, emergency situations, patient triage process, photoplethysmograph, pulse, Remote monitoring, remote monitoring system, Temperature measurement, temperature sensor, temperature sensors, Temperature sensors, Time measurement, vital sign information},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\XM2GJLHS\\7743353.html:text/html}
}

@article{rasche_remote_2019,
	title = {Remote {Photoplethysmographic} {Assessment} of the {Peripheral} {Circulation} in {Critical} {Care} {Patients} {Recovering} {From} {Cardiac} {Surgery}},
	volume = {52},
	issn = {1073-2322},
	url = {https://journals.lww.com/shockjournal/Fulltext/2019/08000/Remote_Photoplethysmographic_Assessment_of_the.6.aspx},
	doi = {10.1097/SHK.0000000000001249},
	abstract = {Purpose: 
        Camera-based photoplethysmography (cbPPG) remotely detects the volume pulse of cardiac ejection in the peripheral circulation. The cbPPG signal is sourced from the cutaneous microcirculation, yields a 2-dimensional intensity map, and is therefore an interesting monitoring technique. In this study, we investigated whether cbPPG is in general sufficiently sensitive to discern hemodynamic conditions.
        Methods: 
        cbPPG recordings of 70 patients recovering from cardiac surgery were analyzed. Photoplethysmograms were processed offline and the optical pulse power (OPP) of cardiac ejection was calculated. Hemodynamic data, image intensity, and patient movements were recorded synchronously. The effects of hemodynamic parameters and measurement conditions on the patient's individual OPP variability and their actual OPP values were calculated in mixed-effects regression models.
        Results: 
        Mean arterial pressure (MAP), pulse pressure (PP), heart rate (HR), and central venous pressure (CVP) significantly explained the individual OPP variability. PP had the highest explanatory power (19.9\%). Averaged OPP significantly increased with PP and MAP (P {\textless} 0.001, respectively) and decreased with higher HR (P = 0.024). CVP had a 2-directional, nonsignificant effect on averaged OPP. Image intensity and patient movements did significantly affect OPP. After adjustment for hemodynamic covariables and measurement conditions, the effect of PP and HR remained unchanged, whereas that of MAP vanished.
        Conclusion: 
        cbPPG is sensitive to hemodynamic parameters in critical care patients. It is a potential application for monitoring the peripheral circulation. Its value in a clinical setting has to be determined.},
	language = {en-US},
	number = {2},
	urldate = {2020-10-20},
	journal = {Shock},
	author = {Rasche, Stefan and Trumpp, Alexander and Schmidt, Martin and Plötze, Katrin and Gätjen, Frederik and Malberg, Hagen and Matschke, Klaus and Rudolf, Matthias and Baum, Fabian and Zaunseder, Sebastian},
	month = aug,
	year = {2019},
	pages = {174--182},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\JMCEIYCA\\Rasche et al. - 2019 - Remote Photoplethysmographic Assessment of the Per.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\LI2WXC6T\\Remote_Photoplethysmographic_Assessment_of_the.6.html:text/html}
}

@article{groves_intensive_2008,
	title = {Intensive care telemedicine: evaluating a model for proactive remote monitoring and intervention in the critical care setting},
	volume = {131},
	issn = {0926-9630},
	shorttitle = {Intensive care telemedicine},
	abstract = {Historically, telemedicine has focused on the application of traditional physician-to-patient (and physician-to-physician) interactions enhanced by two-way video and audio capability. This "one-on-one" interaction via a telemedicine link can dramatically extend a physician's or other caregiver's geographic range and availability. However, this same telemedicine model is most often implemented "on-demand" for a specified time-limited encounter. The remote Intensive Care Unit (ICU) model to be described similarly expands the geographic range of ICU physicians, but also allows a single specialist to simultaneously monitor multiple patients on a continuous basis by leveraging computerized "intelligent" algorithms and an electronic medical record interface. This new application of telemedicine wedded to computer technology facilitates maximum leveraging of specialists' cognitive skills but also mandates significant process changes in how ICU services are provided. In short, the remote ICU represents a "re-engineering" of how ICU care is delivered and establishes a new paradigm for the field of telemedicine, expanding the reach, scope and availability of intensivist specialty expertise.The re-engineering occurs through a number of ways. First, the telemedicine connection is continuously available in a pro-active fashion that can be provided 24 hours a day, 7 days a week (24/7). Secondly, the system utilizes computerized clinical intelligence algorithms with direct electronic links to physiologic, laboratory and lab/pharmacy data as well as patient diagnoses to focus attention on potential adverse outcomes or trends in individual patients and notify caregivers before trends manifest as adverse outcomes. Third, the traditional physician, nurse, and patient relationship is substantially augmented when there is an ICU physician immediately available to address issues in patient care, particularly at night when physicians are less likely to be present at the bedside. The current preliminary data suggest that this system can be quite effective in improving ICU quality of care, thus leading to reductions in the cost of ICU care, ICU patient mortality, ICU patient outliers, and ICU length of stay (LOS). Given the extensive data showing improved ICU outcomes with daily ICU physician participation in care of critically ill patients, and the national shortage of ICU physicians, nurses, and ancillary staff; the electronic ICU system is gaining popularity as an alternative paradigm for the expansion of an ICU team's expertise in the care of the severely ill. Interestingly, internal Quality Improvement (QI) data from several healthcare systems have shown that improved outcomes occur even when remote ICU telemedicine is applied to a pre-existing 24/7 in-house intensivist care model. The reasons for this remain speculative at this point, but pro-active and hourly remote "virtual rounds" on the most critically-ill patients, and use of computerized algorithms in triaging ICU physicians' attention may contribute to the success of this system. Also, we will show how the system supports key elements of error reduction theory even in well-staffed critical care units. Multiple challenges remain before remote ICU systems become more broadly accepted and applied. These include cost of implementation of the system, resistance to the system by ICU physicians and nurses, and integration of data systems and clinical information into the remote electronic ICU model. In this chapter, we will provide background information on error reduction theory and the role of the remote ICU model, review current data supporting use of the remote ICU system, address the current obstacles to effective implementation, and look to the future of the field for solutions to these challenges.},
	language = {eng},
	journal = {Studies in Health Technology and Informatics},
	author = {Groves, Robert H. and Holcomb, Barry W. and Smith, Marshall L.},
	year = {2008},
	pmid = {18305328},
	keywords = {Humans, Monitoring, Physiologic, Telemedicine, Computer Communication Networks, Critical Care, Health Services Needs and Demand, Intensive Care Units, Medically Underserved Area, Remote Consultation},
	pages = {131--146}
}

@article{addison_video-based_2017,
	title = {Video-{Based} {Physiologic} {Monitoring} {During} an {Acute} {Hypoxic} {Challenge}: {Heart} {Rate}, {Respiratory} {Rate}, and {Oxygen} {Saturation}},
	volume = {125},
	issn = {0003-2999},
	shorttitle = {Video-{Based} {Physiologic} {Monitoring} {During} an {Acute} {Hypoxic} {Challenge}},
	url = {https://journals.lww.com/anesthesia-analgesia/Fulltext/2017/09000/Video_Based_Physiologic_Monitoring_During_an_Acute.24.aspx},
	doi = {10.1213/ANE.0000000000001989},
	abstract = {BACKGROUND: 
        The physiologic information contained in the video photoplethysmogram is well documented. However, extracting this information during challenging conditions requires new analysis techniques to capture and process the video image streams to extract clinically useful physiologic parameters. We hypothesized that heart rate, respiratory rate, and oxygen saturation trending can be evaluated accurately from video information during acute hypoxia.
        METHODS: 
        Video footage was acquired from multiple desaturation episodes during a porcine model of acute hypoxia using a standard visible light camera. A novel in-house algorithm was used to extract photoplethysmographic cardiac pulse and respiratory information from the video image streams and process it to extract a continuously reported video-based heart rate (HRvid), respiratory rate (RRvid), and oxygen saturation (SvidO2). This information was then compared with HR and oxygen saturation references from commercial pulse oximetry and the known rate of respiration from the ventilator.
        RESULTS: 
        Eighty-eight minutes of data were acquired during 16 hypoxic episodes in 8 animals. A linear mixed-effects regression showed excellent responses relative to a nonhypoxic reference signal with slopes of 0.976 (95\% confidence interval [CI], 0.973–0.979) for HRvid; 1.135 (95\% CI, 1.101–1.168) for RRvid, and 0.913 (95\% CI, 0.905–0.920) for video-based oxygen saturation. These results were obtained while maintaining continuous uninterrupted vital sign monitoring for the entire study period.
        CONCLUSIONS: 
        Video-based monitoring of HR, RR, and oxygen saturation may be performed with reasonable accuracy during acute hypoxic conditions in an anesthetized porcine hypoxia model using standard visible light camera equipment. However, the study was conducted during relatively low motion. A better understanding of the effect of motion and the effect of ambient light on the video photoplethysmogram may help refine this monitoring technology for use in the clinical environment.},
	language = {en-US},
	number = {3},
	urldate = {2020-10-20},
	journal = {Anesthesia \& Analgesia},
	author = {Addison, Paul S. and Jacquel, Dominique and Foo, David M. H. and Antunes, André and Borg, Ulf R.},
	month = sep,
	year = {2017},
	pages = {860--873},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\JPKC2GFH\\Video_Based_Physiologic_Monitoring_During_an_Acute.24.html:text/html}
}

@article{cobos-torres_non-contact_2018,
	title = {Non-{Contact}, {Simple} {Neonatal} {Monitoring} by {Photoplethysmography}},
	volume = {18},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/18/12/4362},
	doi = {10.3390/s18124362},
	abstract = {This paper presents non-contact vital sign monitoring in neonates, based on image processing, where a standard color camera captures the plethysmographic signal and the heart and breathing rates are processed and estimated online. It is important that the measurements are taken in a non-invasive manner, which is imperceptible to the patient. Currently, many methods have been proposed for non-contact measurement. However, to the best of the authors\&rsquo; knowledge, it has not been possible to identify methods with low computational costs and a high tolerance to artifacts. With the aim of improving contactless measurement results, the proposed method based on the computer vision technique is enhanced to overcome the mentioned drawbacks. The camera is attached to an incubator in the Neonatal Intensive Care Unit and a single area in the neonate\&rsquo;s diaphragm is monitored. Several factors are considered in the stages of image acquisition, as well as in the plethysmographic signal formation, pre-filtering and filtering. The pre-filter step uses numerical analysis techniques to reduce the signal offset. The proposed method decouples the breath rate from the frequency of sinus arrhythmia. This separation makes it possible to analyze independently any cardiac and respiratory dysrhythmias. Nine newborns were monitored with our proposed method. A Bland-Altman analysis of the data shows a close correlation of the heart rates measured with the two approaches (correlation coefficient of 0.94 for heart rate (HR) and 0.86 for breath rate (BR)) with an uncertainty of 4.2 bpm for HR and 4.9 for BR (k = 1). The comparison of our method and another non-contact method considered as a standard independent component analysis (ICA) showed lower central processing unit (CPU) usage for our method (75\% less CPU usage).},
	language = {en},
	number = {12},
	urldate = {2020-10-20},
	journal = {Sensors},
	author = {Cobos-Torres, Juan-Carlos and Abderrahim, Mohamed and Martínez-Orgado, José},
	month = dec,
	year = {2018},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {vital signs, image processing, imaging photoplethysmography, neonatology, respiratory sinus arrhythmia},
	pages = {4362},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\U2VN96PN\\Cobos-Torres et al. - 2018 - Non-Contact, Simple Neonatal Monitoring by Photopl.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\CVTPDT9S\\4362.html:text/html}
}

@article{negishi_contactless_2020,
	title = {Contactless {Vital} {Signs} {Measurement} {System} {Using} {RGB}-{Thermal} {Image} {Sensors} and {Its} {Clinical} {Screening} {Test} on {Patients} with {Seasonal} {Influenza}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/20/8/2171},
	doi = {10.3390/s20082171},
	abstract = {Background: In the last two decades, infrared thermography (IRT) has been applied in quarantine stations for the screening of patients with suspected infectious disease. However, the fever-based screening procedure employing IRT suffers from low sensitivity, because monitoring body temperature alone is insufficient for detecting infected patients. To overcome the drawbacks of fever-based screening, this study aims to develop and evaluate a multiple vital sign (i.e., body temperature, heart rate and respiration rate) measurement system using RGB-thermal image sensors. Methods: The RGB camera measures blood volume pulse (BVP) through variations in the light absorption from human facial areas. IRT is used to estimate the respiration rate by measuring the change in temperature near the nostrils or mouth accompanying respiration. To enable a stable and reliable system, the following image and signal processing methods were proposed and implemented: (1) an RGB-thermal image fusion approach to achieve highly reliable facial region-of-interest tracking, (2) a heart rate estimation method including a tapered window for reducing noise caused by the face tracker, reconstruction of a BVP signal with three RGB channels to optimize a linear function, thereby improving the signal-to-noise ratio and multiple signal classification (MUSIC) algorithm for estimating the pseudo-spectrum from limited time-domain BVP signals within 15 s and (3) a respiration rate estimation method implementing nasal or oral breathing signal selection based on signal quality index for stable measurement and MUSIC algorithm for rapid measurement. We tested the system on 22 healthy subjects and 28 patients with seasonal influenza, using the support vector machine (SVM) classification method. Results: The body temperature, heart rate and respiration rate measured in a non-contact manner were highly similarity to those measured via contact-type reference devices (i.e., thermometer, ECG and respiration belt), with Pearson correlation coefficients of 0.71, 0.87 and 0.87, respectively. Moreover, the optimized SVM model with three vital signs yielded sensitivity and specificity values of 85.7\% and 90.1\%, respectively. Conclusion: For contactless vital sign measurement, the system achieved a performance similar to that of the reference devices. The multiple vital sign-based screening achieved higher sensitivity than fever-based screening. Thus, this system represents a promising alternative for further quarantine procedures to prevent the spread of infectious diseases.},
	language = {en},
	number = {8},
	urldate = {2020-10-20},
	journal = {Sensors},
	author = {Negishi, Toshiaki and Abe, Shigeto and Matsui, Takemi and Liu, He and Kurosawa, Masaki and Kirimoto, Tetsuo and Sun, Guanghao},
	month = jan,
	year = {2020},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {vital signs, contactless measurement, infection diseases, RGB-thermal image processing},
	pages = {2171},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\D6XQTTA3\\Negishi et al. - 2020 - Contactless Vital Signs Measurement System Using R.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\VJZGZ83Q\\2171.html:text/html}
}

@article{villarroel_non-contact_2019,
	title = {Non-contact physiological monitoring of preterm infants in the {Neonatal} {Intensive} {Care} {Unit}},
	volume = {2},
	copyright = {2019 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-019-0199-5},
	doi = {10.1038/s41746-019-0199-5},
	abstract = {The implementation of video-based non-contact technologies to monitor the vital signs of preterm infants in the hospital presents several challenges, such as the detection of the presence or the absence of a patient in the video frame, robustness to changes in lighting conditions, automated identification of suitable time periods and regions of interest from which vital signs can be estimated. We carried out a clinical study to evaluate the accuracy and the proportion of time that heart rate and respiratory rate can be estimated from preterm infants using only a video camera in a clinical environment, without interfering with regular patient care. A total of 426.6 h of video and reference vital signs were recorded for 90 sessions from 30 preterm infants in the Neonatal Intensive Care Unit (NICU) of the John Radcliffe Hospital in Oxford. Each preterm infant was recorded under regular ambient light during daytime for up to four consecutive days. We developed multi-task deep learning algorithms to automatically segment skin areas and to estimate vital signs only when the infant was present in the field of view of the video camera and no clinical interventions were undertaken. We propose signal quality assessment algorithms for both heart rate and respiratory rate to discriminate between clinically acceptable and noisy signals. The mean absolute error between the reference and camera-derived heart rates was 2.3 beats/min for over 76\% of the time for which the reference and camera data were valid. The mean absolute error between the reference and camera-derived respiratory rate was 3.5 breaths/min for over 82\% of the time. Accurate estimates of heart rate and respiratory rate could be derived for at least 90\% of the time, if gaps of up to 30 seconds with no estimates were allowed.},
	language = {en},
	number = {1},
	urldate = {2020-10-20},
	journal = {npj Digital Medicine},
	author = {Villarroel, Mauricio and Chaichulee, Sitthichok and Jorge, João and Davis, Sara and Green, Gabrielle and Arteta, Carlos and Zisserman, Andrew and McCormick, Kenny and Watkinson, Peter and Tarassenko, Lionel},
	month = dec,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--18},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\ZIJHDPZT\\Villarroel et al. - 2019 - Non-contact physiological monitoring of preterm in.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\UNTMSL44\\s41746-019-0199-5.html:text/html}
}

@article{wang_algorithmic_2017,
	title = {Algorithmic {Principles} of {Remote} {PPG}},
	volume = {64},
	issn = {1558-2531},
	doi = {10.1109/TBME.2016.2609282},
	abstract = {This paper introduces a mathematical model that incorporates the pertinent optical and physiological properties of skin reflections with the objective to increase our understanding of the algorithmic principles behind remote photoplethysmography (rPPG). The model is used to explain the different choices that were made in existing rPPG methods for pulse extraction. The understanding that comes from the model can be used to design robust or application-specific rPPG solutions. We illustrate this by designing an alternative rPPG method, where a projection plane orthogonal to the skin tone is used for pulse extraction. A large benchmark on the various discussed rPPG methods shows that their relative merits can indeed be understood from the proposed model.},
	number = {7},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Wang, W. and Brinker, A. C. den and Stuijk, S. and Haan, G. de},
	month = jul,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Humans, Algorithm design and analysis, Algorithms, Biomedical monitoring, Blood Flow Velocity, Blood Volume, Blood Volume Determination, Cameras, Color, Colorimetry, colors, Computer Simulation, feature extraction, Image color analysis, Image Interpretation, Computer-Assisted, Light, Light sources, Mathematical model, medical signal processing, Models, Biological, Monitoring, Ambulatory, Photography, photoplethysmography, Photoplethysmography, pulse extraction, remote photoplethysmography, remote PPG algorithmic principles, remote sensing, Remote Sensing Technology, Reproducibility of Results, Scattering, Radiation, Sensitivity and Specificity, skin, Skin, Skin Physiological Phenomena, skin reflection optical properties, skin reflection physiological properties, skin tone},
	pages = {1479--1491},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\IZUQBPJW\\Wang et al. - 2017 - Algorithmic Principles of Remote PPG.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\NU22EC2P\\7565547.html:text/html}
}

@inproceedings{chen_deepphys_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{DeepPhys}: {Video}-{Based} {Physiological} {Measurement} {Using} {Convolutional} {Attention} {Networks}},
	isbn = {978-3-030-01216-8},
	shorttitle = {{DeepPhys}},
	doi = {10.1007/978-3-030-01216-8_22},
	abstract = {Non-contact video-based physiological measurement has many applications in health care and human-computer interaction. Practical applications require measurements to be accurate even in the presence of large head rotations. We propose the first end-to-end system for video-based measurement of heart and breathing rate using a deep convolutional network. The system features a new motion representation based on a skin reflection model and a new attention mechanism using appearance information to guide motion estimation, both of which enable robust measurement under heterogeneous lighting and major motions. Our approach significantly outperforms all current state-of-the-art methods on both RGB and infrared video datasets. Furthermore, it allows spatial-temporal distributions of physiological signals to be visualized via the attention mechanism.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Chen, Weixuan and McDuff, Daniel},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	pages = {356--373},
	file = {Submitted Version:C\:\\Users\\krish\\Zotero\\storage\\4HQYB6G7\\Chen and McDuff - 2018 - DeepPhys Video-Based Physiological Measurement Us.pdf:application/pdf}
}

@article{massaroni_remote_2020,
	title = {Remote {Respiratory} {Monitoring} in the {Time} of {COVID}-19},
	volume = {11},
	issn = {1664-042X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7274133/},
	doi = {10.3389/fphys.2020.00635},
	urldate = {2020-10-20},
	journal = {Frontiers in Physiology},
	author = {Massaroni, Carlo and Nicolò, Andrea and Schena, Emiliano and Sacchetti, Massimo},
	month = may,
	year = {2020},
	pmid = {32574240},
	pmcid = {PMC7274133},
	file = {PubMed Central Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\FN34RNWU\\Massaroni et al. - 2020 - Remote Respiratory Monitoring in the Time of COVID.pdf:application/pdf}
}

@article{massaroni_non-contact_2019,
	title = {Non-{Contact} {Monitoring} of {Breathing} {Pattern} and {Respiratory} {Rate} via {RGB} {Signal} {Measurement}},
	volume = {19},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6631485/},
	doi = {10.3390/s19122758},
	abstract = {Among all the vital signs, respiratory rate remains the least measured in several scenarios, mainly due to the intrusiveness of the sensors usually adopted. For this reason, all contactless monitoring systems are gaining increasing attention in this field. In this paper, we present a measuring system for contactless measurement of the respiratory pattern and the extraction of breath-by-breath respiratory rate. The system consists of a laptop’s built-in RGB camera and an algorithm for post-processing of acquired video data. From the recording of the chest movements of a subject, the analysis of the pixel intensity changes yields a waveform indicating respiratory pattern. The proposed system has been tested on 12 volunteers, both males and females seated in front of the webcam, wearing both slim-fit and loose-fit t-shirts. The pressure-drop signal recorded at the level of nostrils with a head-mounted wearable device was used as reference respiratory pattern. The two methods have been compared in terms of mean of absolute error, standard error, and percentage error. Additionally, a Bland–Altman plot was used to investigate the bias between methods. Results show the ability of the system to record accurate values of respiratory rate, with both slim-fit and loose-fit clothing. The measuring system shows better performance on females. Bland–Altman analysis showed a bias of −0.01 breaths·min−1, with respiratory rate values between 10 and 43 breaths·min−1. Promising performance has been found in the preliminary tests simulating tachypnea.},
	number = {12},
	urldate = {2020-10-20},
	journal = {Sensors (Basel, Switzerland)},
	author = {Massaroni, Carlo and Lo Presti, Daniela and Formica, Domenico and Silvestri, Sergio and Schena, Emiliano},
	month = jun,
	year = {2019},
	pmid = {31248200},
	pmcid = {PMC6631485},
	file = {PubMed Central Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\RDT4W9NV\\Massaroni et al. - 2019 - Non-Contact Monitoring of Breathing Pattern and Re.pdf:application/pdf}
}

@article{jeong_introducing_2016,
	title = {Introducing {Contactless} {Blood} {Pressure} {Assessment} {Using} a {High} {Speed} {Video} {Camera}},
	volume = {40},
	issn = {1573-689X},
	url = {https://doi.org/10.1007/s10916-016-0439-z},
	doi = {10.1007/s10916-016-0439-z},
	abstract = {Recent studies demonstrated that blood pressure (BP) can be estimated using pulse transit time (PTT). For PTT calculation, photoplethysmogram (PPG) is usually used to detect a time lag in pulse wave propagation which is correlated with BP. Until now, PTT and PPG were registered using a set of body-worn sensors. In this study a new methodology is introduced allowing contactless registration of PTT and PPG using high speed camera resulting in corresponding image-based PTT (iPTT) and image-based PPG (iPPG) generation. The iPTT value can be potentially utilized for blood pressure estimation however extent of correlation between iPTT and BP is unknown. The goal of this preliminary feasibility study was to introduce the methodology for contactless generation of iPPG and iPTT and to make initial estimation of the extent of correlation between iPTT and BP “in vivo.” A short cycling exercise was used to generate BP changes in healthy adult volunteers in three consecutive visits. BP was measured by a verified BP monitor simultaneously with iPTT registration at three exercise points: rest, exercise peak, and recovery. iPPG was simultaneously registered at two body locations during the exercise using high speed camera at 420 frames per second. iPTT was calculated as a time lag between pulse waves obtained as two iPPG’s registered from simultaneous recoding of head and palm areas. The average inter-person correlation between PTT and iPTT was 0.85 ± 0.08. The range of inter-person correlations between PTT and iPTT was from 0.70 to 0.95 (p {\textless} 0.05). The average inter-person coefficient of correlation between SBP and iPTT was -0.80 ± 0.12. The range of correlations between systolic BP and iPTT was from 0.632 to 0.960 with p {\textless} 0.05 for most of the participants. Preliminary data indicated that a high speed camera can be potentially utilized for unobtrusive contactless monitoring of abrupt blood pressure changes in a variety of settings. The initial prototype system was able to successfully generate approximation of pulse transit time and showed high intra-individual correlation between iPTT and BP. Further investigation of the proposed approach is warranted.},
	language = {en},
	number = {4},
	urldate = {2020-10-20},
	journal = {Journal of Medical Systems},
	author = {Jeong, In Cheol and Finkelstein, Joseph},
	month = jan,
	year = {2016},
	pages = {77},
	file = {Springer Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\IUF6N8U8\\Jeong and Finkelstein - 2016 - Introducing Contactless Blood Pressure Assessment .pdf:application/pdf}
}

@article{shao_noncontact_2016,
	title = {Noncontact {Monitoring} of {Blood} {Oxygen} {Saturation} {Using} {Camera} and {Dual}-{Wavelength} {Imaging} {System}},
	volume = {63},
	issn = {0018-9294},
	url = {https://asu.pure.elsevier.com/en/publications/noncontact-monitoring-of-blood-oxygen-saturation-using-camera-and},
	doi = {10.1109/TBME.2015.2481896},
	language = {English (US)},
	number = {6},
	urldate = {2020-10-20},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Shao, Dangdang and Liu, Chenbin and Tsow, Francis and Yang, Yuting and Du, Zijian and Iriya, Rafael and Yu, Hui and Tao, Nongjian},
	month = jun,
	year = {2016},
	pmid = {26415199},
	note = {Publisher: IEEE Computer Society},
	pages = {1091--1098},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\QIAALJP6\\noncontact-monitoring-of-blood-oxygen-saturation-using-camera-and.html:text/html}
}

@article{sun_remote_2017,
	title = {Remote sensing of multiple vital signs using a {CMOS} camera-equipped infrared thermography system and its clinical application in rapidly screening patients with suspected infectious diseases},
	volume = {55},
	issn = {1878-3511},
	doi = {10.1016/j.ijid.2017.01.007},
	abstract = {BACKGROUND: Infrared thermography (IRT) is used to screen febrile passengers at international airports, but it suffers from low sensitivity. This study explored the application of a combined visible and thermal image processing approach that uses a CMOS camera equipped with IRT to remotely sense multiple vital signs and screen patients with suspected infectious diseases.
METHODS: An IRT system that produced visible and thermal images was used for image acquisition. The subjects' respiration rates were measured by monitoring temperature changes around the nasal areas on thermal images; facial skin temperatures were measured simultaneously. Facial blood circulation causes tiny color changes in visible facial images that enable the determination of the heart rate. A logistic regression discriminant function predicted the likelihood of infection within 10s, based on the measured vital signs. Sixteen patients with an influenza-like illness and 22 control subjects participated in a clinical test at a clinic in Fukushima, Japan.
RESULTS: The vital-sign-based IRT screening system had a sensitivity of 87.5\% and a negative predictive value of 91.7\%; these values are higher than those of conventional fever-based screening approaches.
CONCLUSIONS: Multiple vital-sign-based screening efficiently detected patients with suspected infectious diseases. It offers a promising alternative to conventional fever-based screening.},
	language = {eng},
	journal = {International journal of infectious diseases: IJID: official publication of the International Society for Infectious Diseases},
	author = {Sun, Guanghao and Nakayama, Yosuke and Dagdanpurev, Sumiyakhand and Abe, Shigeto and Nishimura, Hidekazu and Kirimoto, Tetsuo and Matsui, Takemi},
	month = feb,
	year = {2017},
	pmid = {28093314},
	pmcid = {PMC7110473},
	keywords = {Humans, Photography, Remote Sensing Technology, Female, Male, Adult, Body Temperature, Communicable Diseases, Feasibility Studies, Fever, Fever screening, Infection control, Japan, Mass screening, Mass Screening, Nose, Skin Temperature, Thermography, Vital signs},
	pages = {113--117},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\62L9ISRE\\Sun et al. - 2017 - Remote sensing of multiple vital signs using a CMO.pdf:application/pdf}
}

@article{poh_noncontact_2010,
author = {Ming-Zher Poh and Daniel J. McDuff and Rosalind W. Picard},
journal = {Opt. Express},
keywords = {Medical optics and biotechnology; Remote sensing and sensors ; Fast Fourier transforms; Image analysis; Light sources; Linear filtering; Magnetic resonance imaging; Power spectra},
number = {10},
pages = {10762--10774},
publisher = {OSA},
title = {Non-contact, automated cardiac pulse measurements using video imaging and blind source separation.},
volume = {18},
month = {May},
year = {2010},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-18-10-10762},
doi = {10.1364/OE.18.010762},
abstract = {Remote measurements of the cardiac pulse can provide comfortable physiological assessment without electrodes. However, attempts so far are non-automated, susceptible to motion artifacts and typically expensive. In this paper, we introduce a new methodology that overcomes these problems. This novel approach can be applied to color video recordings of the human face and is based on automatic face tracking along with blind source separation of the color channels into independent components. Using Bland-Altman and correlation analysis, we compared the cardiac pulse rate extracted from videos recorded by a basic webcam to an FDA-approved finger blood volume pulse (BVP) sensor and achieved high accuracy and correlation even in the presence of movement artifacts. Furthermore, we applied this technique to perform heart rate measurements from three participants simultaneously. This is the first demonstration of a low-cost accurate video-based method for contact-free heart rate measurements that is automated, motion-tolerant and capable of performing concomitant measurements on more than one person at a time.},
}

@article{poh_advancements_2011,
	title = {Advancements in {Noncontact}, {Multiparameter} {Physiological} {Measurements} {Using} a {Webcam}},
	volume = {58},
	issn = {1558-2531},
	doi = {10.1109/TBME.2010.2086456},
	abstract = {We present a simple, low-cost method for measuring multiple physiological parameters using a basic webcam. By applying independent component analysis on the color channels in video recordings, we extracted the blood volume pulse from the facial regions. Heart rate (HR), respiratory rate, and HR variability (HRV, an index for cardiac autonomic activity) were subsequently quantified and compared to corresponding measurements using Food and Drug Administration-approved sensors. High degrees of agreement were achieved between the measurements across all physiological parameters. This technology has significant potential for advancing personal health care and telemedicine.},
	number = {1},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Poh, M. and McDuff, D. J. and Picard, R. W.},
	month = jan,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Humans, Algorithms, remote sensing, heart rate variability, Heart rate variability, biomedical optical imaging, cameras, Video Recording, cardiology, photoplethysmography (PPG), image sensors, blood flow measurement, Female, Image Processing, Computer-Assisted, Male, Monitoring, Physiologic, independent component analysis, health care, noncontact, Adult, Autonomic nervous system, Biomedical measurements, blood volume pulse, blood volume pulse (BVP), cardiac autonomic activity index, color channels, facial regions, Frequency measurement, Hafnium, heart rate variability (HRV), independent component analysis (ICA), Internet, multiparameter physiological measurements, multiple physiological parameter measurement, noncontact physiological measurements, personal health care, Resonant frequency, respiration, respiratory rate, Sensors, telemedicine, Telemedicine, video recordings, webcam},
	pages = {7--11},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\QHBTKZ7I\\5599853.html:text/html}
}

@article{haan_robust_2013,
	title = {Robust {Pulse} {Rate} {From} {Chrominance}-{Based} {rPPG}},
	volume = {60},
	issn = {1558-2531},
	doi = {10.1109/TBME.2013.2266196},
	abstract = {Remote photoplethysmography (rPPG) enables contactless monitoring of the blood volume pulse using a regular camera. Recent research focused on improved motion robustness, but the proposed blind source separation techniques (BSS) in RGB color space show limited success. We present an analysis of the motion problem, from which far superior chrominance-based methods emerge. For a population of 117 stationary subjects, we show our methods to perform in 92\% good agreement (±1.96σ) with contact PPG, with RMSE and standard deviation both a factor of 2 better than BSS-based methods. In a fitness setting using a simple spectral peak detector, the obtained pulse-rate for modest motion (bike) improves from 79\% to 98\% correct, and for vigorous motion (stepping) from less than 11\% to more than 48\% correct. We expect the greatly improved robustness to considerably widen the application scope of the technology.},
	number = {10},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Haan, G. de and Jeanne, V.},
	month = oct,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Humans, Algorithms, Biomedical monitoring, Blood Flow Velocity, Cameras, Color, Colorimetry, Image color analysis, Photography, photoplethysmography, Photoplethysmography, remote photoplethysmography, remote sensing, Reproducibility of Results, Sensitivity and Specificity, Skin, Skin Physiological Phenomena, blood, medical image processing, camera, Signal to noise ratio, blind source separation technique, Blood, blood volume pulse monitoring, BSS-based method, chrominance-based rPPG, Diagnosis, Computer-Assisted, haemodynamics, Heart Rate, image analysis, mean square error methods, photoplethysmography (PPG), pulse rate, RGB color space, RMSE, Robustness, spectral peak detector, standard deviation, statistical analysis},
	pages = {2878--2886},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\4H82Q7CS\\6523142.html:text/html}
}

@article{de_haan_improved_2014,
	title = {Improved motion robustness of remote-{PPG} by using the blood volume pulse signature},
	volume = {35},
	issn = {1361-6579},
	doi = {10.1088/0967-3334/35/9/1913},
	abstract = {Remote photoplethysmography (rPPG) enables contact-free monitoring of the blood volume pulse using a color camera. Essentially, it detects the minute optical absorption changes caused by blood volume variations in the skin. In this paper, we show that the different absorption spectra of arterial blood and bloodless skin cause the variations to occur along a very specific vector in a normalized RGB-space. The exact vector can be determined for a given light spectrum and for given transfer characteristics of the optical filters in the camera. We show that this 'signature' can be used to design an rPPG algorithm with a much better motion robustness than the recent methods based on blind source separation, and even better than the chrominance-based methods we published earlier. Using six videos recorded in a gym, with four subjects exercising on a range of fitness devices, we confirm the superior motion robustness of our newly proposed rPPG methods. A simple peak detector in the frequency domain returns the correct pulse-rate for 68\% of total measurements compared to 60\% for the best previous method, while the SNR of the pulse-signal improves from  - 5 dB to  - 4 dB. For a large population of 117 stationary subjects we prove that the accuracy is comparable to the best previous method, although the SNR of the pulse-signal drops from  + 8.4 dB to  + 7.6 dB. We expect the improved motion robustness to significantly widen the application scope of the rPPG-technique.},
	language = {eng},
	number = {9},
	journal = {Physiological Measurement},
	author = {de Haan, G. and van Leest, A.},
	year = {2014},
	pmid = {25159049},
	pages = {1913--1926},
	file = {Submitted Version:C\:\\Users\\krish\\Zotero\\storage\\6526KNQ8\\de Haan and van Leest - 2014 - Improved motion robustness of remote-PPG by using .pdf:application/pdf}
}

@article{wang_novel_2016,
	title = {A {Novel} {Algorithm} for {Remote} {Photoplethysmography}: {Spatial} {Subspace} {Rotation}},
	volume = {63},
	issn = {1558-2531},
	shorttitle = {A {Novel} {Algorithm} for {Remote} {Photoplethysmography}},
	doi = {10.1109/TBME.2015.2508602},
	abstract = {In this paper, we propose a conceptually novel algorithm, namely “Spatial Subspace Rotation” (2SR), that improves the robustness of remote photoplethysmography. Based on the assumption of 1) spatially redundant pixel-sensors of a camera, and 2) a well-defined skin mask, our core idea is to estimate a spatial subspace of skin-pixels and measure its temporal rotation for pulse extraction, which does not require skin-tone or pulse-related priors in contrast to existing algorithms. The proposed algorithm is thoroughly assessed on a benchmark dataset containing 54 videos, which includes challenges of various skin-tones, body-motions in complex illuminance conditions, and pulse-rate recovery after exercise. The experimental results show that given a well-defined skin mask, 2SR outperforms the popular ICA-based approach and two state-of-the-art algorithms (CHROM and PBV). When comparing the pulse frequency spectrum, 2SR improves on average the SNR of ICA by 2.22 dB, CHROM by 1.56 dB, and PBV by 1.95 dB. When comparing the instant pulse-rate, 2SR improves on average the Pearson correlation and precision of ICA by 47\% and 65\%, CHROM by 22\% and 23\%, and PBV by 21\% and 39\%. ANOVA confirms the significant improvement of 2SR in peak-to-peak accuracy. The proposed 2SR algorithm is very simple to use and extend, i.e., the implementation only requires a few lines MATLAB code.},
	number = {9},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Wang, W. and Stuijk, S. and Haan, G. de},
	month = sep,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Algorithms, Biomedical monitoring, Blood Volume, Blood Volume Determination, Cameras, Color, Colorimetry, colors, Monitoring, Ambulatory, Photography, photoplethysmography, Photoplethysmography, pulse extraction, remote photoplethysmography, remote sensing, Reproducibility of Results, Sensitivity and Specificity, Skin, medical image processing, camera, cameras, cardiology, Blood, Robustness, biomedical equipment, independent component analysis, 2SR algorithm, 2SR outperforms, benchmark dataset, body-motions, complex illuminance conditions, ICA-based approach, image denoising, MATLAB code, Pearson correlation and precision, pulse frequency spectrum, pulse-rate recovery, reviews, Rotation, skin mask, Skin Pigmentation, skin-tone, SNR, spatial subspace rotation, spatially redundant pixel-sensors, state-of-the-art algorithms, temporal rotation},
	pages = {1974--1984},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\5JIJCZ9S\\7355301.html:text/html}
}

@article{tsouri_constrained_2012,
	title = {Constrained independent component analysis approach to nonobtrusive pulse rate measurements},
	volume = {17},
	issn = {1083-3668, 1560-2281},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-17/issue-7/077011/Constrained-independent-component-analysis-approach-to-nonobtrusive-pulse-rate-measurements/10.1117/1.JBO.17.7.077011.short},
	doi = {10.1117/1.JBO.17.7.077011},
	abstract = {Nonobtrusive pulse rate measurement using a webcam is considered. We demonstrate how state-of-the-art algorithms based on independent component analysis suffer from a sorting problem which hinders their performance, and propose a novel algorithm based on constrained independent component analysis to improve performance. We present how the proposed algorithm extracts a photoplethysmography signal and resolves the sorting problem. In addition, we perform a comparative study between the proposed algorithm and state-of-the-art algorithms over 45 video streams using a finger probe oxymeter for reference measurements. The proposed algorithm provides improved accuracy: the root mean square error is decreased from 20.6 and 9.5 beats per minute (bpm) for existing algorithms to 3.5 bpm for the proposed algorithm. An error of 3.5 bpm is within the inaccuracy expected from the reference measurements. This implies that the proposed algorithm provided performance of equal accuracy to the finger probe oximeter.},
	number = {7},
	urldate = {2020-10-20},
	journal = {Journal of Biomedical Optics},
	author = {Tsouri, Gill R. and Kyal, Survi and Dianat, Sohail A. and Mestha, Lalilt K.},
	month = jul,
	year = {2012},
	note = {Publisher: International Society for Optics and Photonics},
	pages = {077011},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\HHU57JML\\Tsouri et al. - 2012 - Constrained independent component analysis approac.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\NAQS9XSK\\1.JBO.17.7.077011.html:text/html}
}

@article{wang_exploiting_2015,
	title = {Exploiting {Spatial} {Redundancy} of {Image} {Sensor} for {Motion} {Robust} {rPPG}},
	volume = {62},
	issn = {1558-2531},
	doi = {10.1109/TBME.2014.2356291},
	abstract = {Remote photoplethysmography (rPPG) techniques can measure cardiac activity by detecting pulse-induced color variations on human skin using an RGB camera. State-of-the-art rPPG methods are sensitive to subject body motions (e.g., motion-induced color distortions). This study proposes a novel framework to improve the motion robustness of rPPG. The basic idea of this paper originates from the observation that a camera can simultaneously sample multiple skin regions in parallel, and each of them can be treated as an independent sensor for pulse measurement. The spatial redundancy of an image sensor can thus be exploited to distinguish the pulse signal from motion-induced noise. To this end, the pixel-based rPPG sensors are constructed to estimate a robust pulse signal using motion-compensated pixel-to-pixel pulse extraction, spatial pruning, and temporal filtering. The evaluation of this strategy is not based on a full clinical trial, but on 36 challenging benchmark videos consisting of subjects that differ in gender, skin types, and performed motion categories. Experimental results show that the proposed method improves the SNR of the state-of-the-art rPPG technique from 3.34 to 6.76 dB, and the agreement (±1.96σ) with instantaneous reference pulse rate from 55\% to 80\% correct. ANOVA with post hoc comparison shows that the improvement on motion robustness is significant. The rPPG method developed in this study has a performance that is very close to that of the contact-based sensor under realistic situations, while its computational efficiency allows real-time processing on an off-the-shelf computer.},
	number = {2},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Wang, W. and Stuijk, S. and Haan, G. de},
	month = feb,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Humans, Algorithms, Biomedical monitoring, Blood Flow Velocity, Color, Colorimetry, Image color analysis, Image Interpretation, Computer-Assisted, photoplethysmography, Photoplethysmography, remote sensing, Reproducibility of Results, Sensitivity and Specificity, skin, Skin, Skin Physiological Phenomena, image motion analysis, medical image processing, Face, Tracking, patient monitoring, Robustness, Artifacts, Motion, signal-to-noise ratio, video cameras, image sensors, video camera, ANOVA, body motion sensitivity, cardiac activity measurement, cardiovascular system, human skin, image sensor spatial redundancy, independent pulse measurement sensor, instantaneous reference pulse rate, motion analysis, motion robust rPPG, motion-compensated pulse extraction, motion-induced color distortions, motion-induced noise, Noise, noise figure 3.34 dB to 6.76 dB, pixel-based rPPG sensors, pixel-to-pixel pulse extraction, post hoc comparison, pulse-induced color variation detection, real-time computer processing, remote photoplethysmography techniques, RGB camera, robust pulse signal estimation, rPPG method computational efficiency, rPPG methods, rPPG motion robustness, rPPG sensor construction, rPPG technique SNR, rPPG techniques, simultaneous multiple skin region sampling, spatial pruning, spatial redundancy exploitation, subject gender, subject motion, subject skin types, temporal filtering, Transducers},
	pages = {415--425},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\6WYUSN8U\\Wang et al. - 2015 - Exploiting Spatial Redundancy of Image Sensor for .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\INW3VMCU\\6894148.html:text/html}
}

@inproceedings{nowara_meta-analysis_2020,
	title = {A {Meta}-{Analysis} of the {Impact} of {Skin} {Tone} and {Gender} on {Non}-{Contact} {Photoplethysmography} {Measurements}},
	url = {https://openaccess.thecvf.com/content_CVPRW_2020/html/w19/Nowara_A_Meta-Analysis_of_the_Impact_of_Skin_Tone_and_Gender_CVPRW_2020_paper.html},
	urldate = {2020-10-20},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
	author = {Nowara, Ewa M. and McDuff, Daniel and Veeraraghavan, Ashok},
	year = {2020},
	pages = {284--285},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\KRZVZV4V\\Nowara et al. - 2020 - A Meta-Analysis of the Impact of Skin Tone and Gen.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\HY3ZUP8U\\Nowara_A_Meta-Analysis_of_the_Impact_of_Skin_Tone_and_Gender_CVPRW_2020_paper.html:text/html}
}

@inproceedings{li_remote_2014,
	title = {Remote {Heart} {Rate} {Measurement} from {Face} {Videos} under {Realistic} {Situations}},
	doi = {10.1109/CVPR.2014.543},
	abstract = {Heart rate is an important indicator of people's physiological state. Recently, several papers reported methods to measure heart rate remotely from face videos. Those methods work well on stationary subjects under well controlled conditions, but their performance significantly degrades if the videos are recorded under more challenging conditions, specifically when subjects' motions and illumination variations are involved. We propose a framework which utilizes face tracking and Normalized Least Mean Square adaptive filtering methods to counter their influences. We test our framework on a large difficult and public database MAHNOB-HCI and demonstrate that our method substantially outperforms all previous methods. We also use our method for long term heart rate monitoring in a game evaluation scenario and achieve promising results.},
	booktitle = {2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Li, X. and Chen, J. and Zhao, G. and Pietikäinen, M.},
	month = jun,
	year = {2014},
	note = {ISSN: 1063-6919},
	keywords = {medical image processing, video signal processing, Face, face recognition, Tracking, cardiology, face tracking, Heart rate, Lighting, face videos, Databases, illumination variation, adaptive filters, biomedical measurement, computer games, filtering theory, game evaluation scenario, Green products, heart rate monitoring, human computer interaction, least mean squares methods, MAHNOB-HCI, normalized least mean square adaptive filtering method, physiological state, public database, remote heart rate measurement, subject motions variation, video recording, Videos},
	pages = {4264--4271},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\TGJFXQNM\\6909939.html:text/html}
}

@inproceedings{spetlik_visual_2018,
	title = {Visual {Heart} {Rate} {Estimation} with {Convolutional} {Neural} {Network}},
	abstract = {We propose a novel two-step convolutional neural network to estimate a heart rate from a sequence of facial images. The network is trained end-to-end by alternating optimization and validated on three publicly available datasets yielding state-of-the-art results against three baseline methods. The network performs better by a 40\% margin to the state-of-the-art method on a newly collected dataset. A challenging dataset of 204 fitness-themed videos is introduced. The dataset is designed to test the robustness of heart rate estimation methods to illumination changes and subject’s motion. 17 subjects perform 4 activities (talking, rowing, exercising on a stationary bike and an elliptical trainer) in 3 lighting setups. Each activity is captured by two RGB web-cameras, one is placed on a tripod, the other is attached to the fitness machine which vibrates significantly. Subject’s age ranges from 20 to 53 years, the mean heart rate is ≈ 110, the standard deviation ≈ 25.},
	booktitle = {{BMVC}},
	author = {Spetlík, Radim and Franc, Vojtech and Cech, J. and Matas, Jiri},
	year = {2018}
}

@inproceedings{yu_remote_2019,
	title = {Remote {Heart} {Rate} {Measurement} {From} {Highly} {Compressed} {Facial} {Videos}: {An} {End}-to-{End} {Deep} {Learning} {Solution} {With} {Video} {Enhancement}},
	shorttitle = {Remote {Heart} {Rate} {Measurement} {From} {Highly} {Compressed} {Facial} {Videos}},
	doi = {10.1109/ICCV.2019.00024},
	abstract = {Remote photoplethysmography (rPPG), which aims at measuring heart activities without any contact, has great potential in many applications (e.g., remote healthcare). Existing rPPG approaches rely on analyzing very fine details of facial videos, which are prone to be affected by video compression. Here we propose a two-stage, end-to-end method using hidden rPPG information enhancement and attention networks, which is the first attempt to counter video compression loss and recover rPPG signals from highly compressed videos. The method includes two parts: 1) a Spatio-Temporal Video Enhancement Network (STVEN) for video enhancement, and 2) an rPPG network (rPPGNet) for rPPG signal recovery. The rPPGNet can work on its own for robust rPPG measurement, and the STVEN network can be added and jointly trained to further boost the performance especially on highly compressed videos. Comprehensive experiments are performed on two benchmark datasets to show that, 1) the proposed method not only achieves superior performance on compressed videos with high-quality videos pair, 2) it also generalizes well on novel data with only compressed videos available, which implies the promising potential for real-world applications.},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Yu, Z. and Peng, W. and Li, X. and Hong, X. and Zhao, G.},
	month = oct,
	year = {2019},
	note = {ISSN: 2380-7504},
	keywords = {feature extraction, photoplethysmography, remote photoplethysmography, Skin, image motion analysis, medical image processing, video signal processing, face recognition, patient monitoring, cardiology, image sequences, Standards, Machine learning, learning (artificial intelligence), Convolution, remote heart rate measurement, Videos, attention networks, Bit rate, data compression, end-to-end deep learning solution, end-to-end method, heart activities, high-quality videos pair, highly compressed facial videos, highly compressed videos, remote healthcare, robust rPPG measurement, rPPG approaches, rPPG network, rPPG signal recovery, spatio-temporal video enhancement network, STVEN network, video coding, Video compression, video compression loss},
	pages = {151--160},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\NHNY63IR\\9010965.html:text/html;Submitted Version:C\:\\Users\\krish\\Zotero\\storage\\D8GAZ8PZ\\Yu et al. - 2019 - Remote Heart Rate Measurement From Highly Compress.pdf:application/pdf}
}

@article{yu_remote_2019-1,
	title = {Remote {Photoplethysmograph} {Signal} {Measurement} from {Facial} {Videos} {Using} {Spatio}-{Temporal} {Networks}},
	volume = {1905},
	url = {http://adsabs.harvard.edu/abs/2019arXiv190502419Y},
	abstract = {Recent studies demonstrated that the average heart rate (HR) can be 
measured from facial videos based on non-contact remote
photoplethysmography (rPPG). However for many medical applications
(e.g., atrial fibrillation (AF) detection) knowing only the average HR
is not sufficient, and measuring precise rPPG signals from face for
heart rate variability (HRV) analysis is needed. Here we propose an rPPG
measurement method, which is the first work to use deep spatio-temporal
networks for reconstructing precise rPPG signals from raw facial videos.
With the constraint of trend-consistency with ground truth pulse curves,
our method is able to recover rPPG signals with accurate pulse peaks.
Comprehensive experiments are conducted on two benchmark datasets, and
results demonstrate that our method can achieve superior performance on
both HR and HRV levels comparing to the state-of-the-art methods. We
also achieve promising results of using reconstructed rPPG signals for
AF detection and emotion recognition.},
	urldate = {2020-10-20},
	journal = {arXiv e-prints},
	author = {Yu, Zitong and Li, Xiaobai and Zhao, Guoying},
	month = may,
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {arXiv:1905.02419},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\KFG7GPXP\\Yu et al. - 2019 - Remote Photoplethysmograph Signal Measurement from.pdf:application/pdf}
}

@article{mcduff_iphys_2019,
	title = {{iPhys}: {An} {Open} {Non}-{Contact} {Imaging}-{Based} {Physiological} {Measurement} {Toolbox}},
	shorttitle = {{iPhys}},
	url = {http://arxiv.org/abs/1901.04366},
	abstract = {Imaging-based, non-contact measurement of physiology (including imaging photoplethysmography and imaging ballistocardiography) is a growing field of research. There are several strengths of imaging methods that make them attractive. They remove the need for uncomfortable contact sensors and can enable spatial and concomitant measurement from a single sensor. Furthermore, cameras are ubiquitous and often low-cost solutions for sensing. Open source toolboxes help accelerate the progress of research by providing a means to compare new approaches against standard implementations of the state-of-the-art. We present an open source imaging-based physiological measurement toolbox with implementations of many of the most frequently employed computational methods. We hope that this toolbox will contribute to the advancement of non-contact physiological sensing methods.},
	urldate = {2020-10-20},
	journal = {arXiv:1901.04366 [cs]},
	author = {McDuff, Daniel and Blackford, Ethan},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.04366},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\krish\\Zotero\\storage\\KEUTLYBF\\McDuff and Blackford - 2019 - iPhys An Open Non-Contact Imaging-Based Physiolog.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\krish\\Zotero\\storage\\HHI7DACL\\1901.html:text/html}
}

@inproceedings{tulyakov_self-adaptive_2016,
	title = {Self-{Adaptive} {Matrix} {Completion} for {Heart} {Rate} {Estimation} from {Face} {Videos} under {Realistic} {Conditions}},
	doi = {10.1109/CVPR.2016.263},
	abstract = {Recent studies in computer vision have shown that, while practically invisible to a human observer, skin color changes due to blood flow can be captured on face videos and, surprisingly, be used to estimate the heart rate (HR). While considerable progress has been made in the last few years, still many issues remain open. In particular, state of-the-art approaches are not robust enough to operate in natural conditions (e.g. in case of spontaneous movements, facial expressions, or illumination changes). Opposite to previous approaches that estimate the HR by processing all the skin pixels inside a fixed region of interest, we introduce a strategy to dynamically select face regions useful for robust HR estimation. Our approach, inspired by recent advances on matrix completion theory, allows us to predict the HR while simultaneously discover the best regions of the face to be used for estimation. Thorough experimental evaluation conducted on public benchmarks suggests that the proposed approach significantly outperforms state-of the-art HR estimation methods in naturalistic conditions.},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Tulyakov, S. and Alameda-Pineda, X. and Ricci, E. and Yin, L. and Cohn, J. F. and Sebe, N.},
	month = jun,
	year = {2016},
	note = {ISSN: 1063-6919},
	keywords = {Feature extraction, video signal processing, Face, face recognition, Heart rate, Robustness, Computer vision, Estimation, computer vision, Videos, estimation theory, face region selection, face video, feature selection, heart rate estimation, HR estimation, matrix algebra, realistic condition, self-adaptive matrix completion},
	pages = {2396--2404},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\B7CEGCJX\\7780632.html:text/html;Submitted Version:C\:\\Users\\krish\\Zotero\\storage\\WLCSCJMY\\Tulyakov et al. - 2016 - Self-Adaptive Matrix Completion for Heart Rate Est.pdf:application/pdf}
}

@article{kumar_distanceppg_2015,
	title = {{DistancePPG}: {Robust} non-contact vital signs monitoring using a camera},
	volume = {6},
	copyright = {\&\#169; 2015 Optical Society of America},
	issn = {2156-7085},
	shorttitle = {{DistancePPG}},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-6-5-1565},
	doi = {10.1364/BOE.6.001565},
	abstract = {Vital signs such as pulse rate and breathing rate are currently measured using contact probes. But, non-contact methods for measuring vital signs are desirable both in hospital settings (e.g. in NICU) and for ubiquitous in-situ health tracking (e.g. on mobile phone and computers with webcams). Recently, camera-based non-contact vital sign monitoring have been shown to be feasible. However, camera-based vital sign monitoring is challenging for people with darker skin tone, under low lighting conditions, and/or during movement of an individual in front of the camera. In this paper, we propose distancePPG, a new camera-based vital sign estimation algorithm which addresses these challenges. DistancePPG proposes a new method of combining skin-color change signals from different tracked regions of the face using a weighted average, where the weights depend on the blood perfusion and incident light intensity in the region, to improve the signal-to-noise ratio (SNR) of camera-based estimate. One of our key contributions is a new automatic method for determining the weights based only on the video recording of the subject. The gains in SNR of camera-based PPG estimated using distancePPG translate into reduction of the error in vital sign estimation, and thus expand the scope of camera-based vital sign monitoring to potentially challenging scenarios. Further, a dataset will be released, comprising of synchronized video recordings of face and pulse oximeter based ground truth recordings from the earlobe for people with different skin tones, under different lighting conditions and for various motion scenarios.},
	language = {EN},
	number = {5},
	urldate = {2020-10-20},
	journal = {Biomedical Optics Express},
	author = {Kumar, Mayank and Veeraraghavan, Ashok and Sabharwal, Ashutosh},
	month = may,
	year = {2015},
	note = {Publisher: Optical Society of America},
	pages = {1565--1588},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\EEHZ3DEN\\Kumar et al. - 2015 - DistancePPG Robust non-contact vital signs monito.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\LIZ2WI7R\\fulltext.html:text/html}
}

@article{bobbia_unsupervised_2019,
	series = {Award {Winning} {Papers} from the 23rd {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	title = {Unsupervised skin tissue segmentation for remote photoplethysmography},
	volume = {124},
	issn = {0167-8655},
	url = {http://www.sciencedirect.com/science/article/pii/S0167865517303860},
	doi = {10.1016/j.patrec.2017.10.017},
	abstract = {Segmentation is a critical step for many algorithms, especially for remote photoplethysmography (rPPG) applications as only the skin surface provides information. Moreover, it has been shown that the rPPG signal is not distributed homogeneously across the skin. Most of the time, algorithms get input information from face detection provided by a supervised learning of physical appearance and skin pixel selection. However, both methods show several limitations. In this paper, we propose a simple approach to implicitly select skin tissues based on their distinct pulsatility feature. The input video frames are decomposed into several temporal superpixels from which the pulse signals are extracted. A pulsatility measure from each temporal superpixel is then used to merge the pulse traces and estimate the photoplethysmogram signal. Since the most pulsatile signals provide high quality information, areas where the information is predominant are favored. We evaluated our contribution using a new publicly available dataset dedicated to rPPG algorithms comparison. The results of our experiments show that our method outperforms state of the art algorithms, without any critical face or skin detection.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Pattern Recognition Letters},
	author = {Bobbia, Serge and Macwan, Richard and Benezeth, Yannick and Mansouri, Alamin and Dubois, Julien},
	month = jun,
	year = {2019},
	keywords = {Image processing, Living skin tissue segmentation, Remote photoplethysmography, Unsupervised},
	pages = {82--90},
	file = {ScienceDirect Snapshot:C\:\\Users\\krish\\Zotero\\storage\\7DHIQ47D\\S0167865517303860.html:text/html}
}

@inproceedings{hsu_deep_2017,
	title = {Deep learning with time-frequency representation for pulse estimation from facial videos},
	doi = {10.1109/BTAS.2017.8272721},
	abstract = {Accurate pulse estimation is of pivotal importance in acquiring the critical physical conditions of human subjects under test, and facial video based pulse estimation approaches recently gained attention owing to their simplicity. In this work, we have endeavored to develop a novel deep learning approach as the core part for pulse (heart rate) estimation by using a common RGB camera. Our approach consists of four steps. We first begin by detecting the face and its landmarks, and thereby locate the required facial ROI. In Step 2, we extract the sample mean sequences of the R, G, and B channels from the facial ROI, and explore three processing schemes for noise removal and signal enhancement. In Step 3, the Short-Time Fourier Transform (STFT) is employed to build the 2D Time-Frequency Representations (TFRs) of the sequences. The 2D TFR enables the formulation of the pulse estimation as an image-based classification problem, which can be solved in Step 4 by a deep Con-volutional Neural Network (CNN). Our approach is one of the pioneering works for attempting real-time pulse estimation using a deep learning framework. We have developed a pulse database, called the Pulse from Face (PFF), and used it to train the CNN. The PFF database will be made publicly available to advance related research. When compared to state-of-the-art pulse estimation approaches on the standard MAHNOB-HCI database, the proposed approach has exhibited superior performance.},
	booktitle = {2017 {IEEE} {International} {Joint} {Conference} on {Biometrics} ({IJCB})},
	author = {Hsu, G. and Ambikapathi, A. and Chen, M.},
	month = oct,
	year = {2017},
	note = {ISSN: 2474-9699},
	keywords = {feature extraction, video signal processing, Face, face recognition, CNN, image classification, image colour analysis, image segmentation, Machine learning, Estimation, image sensors, Databases, learning (artificial intelligence), human computer interaction, Videos, 2D TFR, 2D Time-Frequency Representations, accurate pulse estimation, common RGB camera, critical physical conditions, deep Convolutional Neural Network, deep learning approach, deep learning framework, Detectors, emotion recognition, facial video based pulse estimation approaches, facial videos, feedforward neural nets, Fourier transforms, human subjects, MAHNOB-HCI database, noise removal, PFF database, pulse database, real-time pulse estimation, required facial ROI, sample mean sequences, Short-Time Fourier Transform, signal enhancement, STFT, time-frequency analysis, Time-frequency analysis, time-frequency representation},
	pages = {383--389},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\4HMS3HER\\8272721.html:text/html}
}

@article{song_new_2020,
	title = {New insights on super-high resolution for video-based heart rate estimation with a semi-blind source separation method},
	volume = {116},
	issn = {0010-4825},
	url = {http://www.sciencedirect.com/science/article/pii/S0010482519303944},
	doi = {10.1016/j.compbiomed.2019.103535},
	abstract = {Remote photoplethysmography (rPPG), a non-contact technique to estimate heart rates (HR) from video recordings, has attracted much attention from researchers in recent years. It is well-known that rPPG signals can be extracted from low-resolution videos. However, the measurement quality may degrade due to camera quantization noise if only a small number of pixels are within the skin region of interest. The purpose of this paper is to comprehensively investigate the benefit of using a super-high resolution for the rPPG-based HR estimation under various shooting distances. A new semi-blind source separation (semi-BSS) rPPG method, which is proposed to combine the advantages of BSS and model-based methods, is fully tested on both the public UBFC-RPPG and self-collected video datasets. The experimental results demonstrate that the new semi-BSS method outperforms several existing techniques. A consistent and remarkable improvement on the rPPG signal quality has been observed with the super-high resolution when the shooting distance is no less than 1.0 m. This indicates that selecting an appropriate resolution based on a given shooting distance also plays a crucial role to improve the quality of rPPG measurements.},
	language = {en},
	urldate = {2020-10-20},
	journal = {Computers in Biology and Medicine},
	author = {Song, Rencheng and Zhang, Senle and Cheng, Juan and Li, Chang and Chen, Xun},
	month = jan,
	year = {2020},
	keywords = {Remote photoplethysmography, Camera quantization noise, Heart rate estimation, Semi-blind source separation, Video resolution},
	pages = {103535}
}

@inproceedings{li_model-based_2020,
	address = {Prague, Czech Republic},
	title = {Model-based {Region} of {Interest} {Segmentation} for {Remote} {Photoplethysmography}},
	volume = {4},
	isbn = {978-989-758-354-4},
	url = {https://www.scitepress.org/PublicationsDetail.aspx?ID=2AmX9UVJhmY=&t=1},
	abstract = {Digital Library},
	urldate = {2020-10-20},
	booktitle = {Proceedings of the 14th {International} {Joint} {Conference} on {Computer} {Vision}, {Imaging} and {Computer} {Graphics} {Theory} and {Applications} ({VISAPP})},
	author = {Li, Peixi and Benezeth, Yannick and Nakamura, Keisuke and Gomez, Randy and Yang, Fan},
	month = oct,
	year = {2020},
	pages = {383--388},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\N2794RTP\\PublicationsDetail.html:text/html}
}

@article{zhang_joint_2016,
	title = {Joint {Face} {Detection} and {Alignment} {Using} {Multitask} {Cascaded} {Convolutional} {Networks}},
	volume = {23},
	issn = {1558-2361},
	doi = {10.1109/LSP.2016.2603342},
	abstract = {Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations, and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this letter, we propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance. In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner. In addition, we propose a new online hard sample mining strategy that further improves the performance in practice. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging face detection dataset and benchmark and WIDER FACE benchmarks for face detection, and annotated facial landmarks in the wild benchmark for face alignment, while keeps real-time performance.},
	number = {10},
	journal = {IEEE Signal Processing Letters},
	author = {Zhang, K. and Zhang, Z. and Li, Z. and Qiao, Y.},
	month = oct,
	year = {2016},
	note = {Conference Name: IEEE Signal Processing Letters},
	keywords = {Face, face recognition, face detection, Training, learning (artificial intelligence), Face detection, Convolution, deep learning approach, Detectors, annotated facial landmark, Benchmark testing, Cascaded convolutional neural network (CNN), coarse-to-fine manner, Computer architecture, data mining, deep cascaded multitask framework, detection benchmark, detection dataset, face alignment, face location prediction, joint face detection and alignment, landmark location prediction, multitask cascaded convolutional network, online hard sample mining strategy, state-of-the-art technique, unconstrained environment, WIDER FACE benchmark},
	pages = {1499--1503},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\AB7S3SJJ\\7553523.html:text/html;Submitted Version:C\:\\Users\\krish\\Zotero\\storage\\KY8RCDPJ\\Zhang et al. - 2016 - Joint Face Detection and Alignment Using Multitask.pdf:application/pdf}
}

@inproceedings{hasinoff_noise-optimal_2010,
	title = {Noise-optimal capture for high dynamic range photography},
	doi = {10.1109/CVPR.2010.5540167},
	abstract = {Taking multiple exposures is a well-established approach both for capturing high dynamic range (HDR) scenes and for noise reduction. But what is the optimal set of photos to capture? The typical approach to HDR capture uses a set of photos with geometrically-spaced exposure times, at a fixed ISO setting (typically ISO 100 or 200). By contrast, we show that the capture sequence with optimal worst-case performance, in general, uses much higher and variable ISO settings, and spends longer capturing the dark parts of the scene. Based on a detailed model of noise, we show that optimal capture can be formulated as a mixed integer programming problem. Compared to typical HDR capture, our method lets us achieve higher worst-case SNR in the same capture time (for some cameras, up to 19 dB improvement in the darkest regions), or much faster capture for the same minimum acceptable level of SNR. Our experiments demonstrate this advantage for both real and synthetic scenes.},
	booktitle = {2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Hasinoff, S. W. and Durand, F. and Freeman, W. T.},
	month = jun,
	year = {2010},
	note = {ISSN: 1063-6919},
	keywords = {Cameras, Photography, Signal to noise ratio, image sequences, image denoising, SNR, Additive noise, Computer science, Dynamic range, HDR, high dynamic range photography, integer programming, ISO standards, Layout, Linear programming, mixed integer programming problem, noise optimal capture, noise reduction, Noise reduction, photography},
	pages = {553--560},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\ALWIGV7J\\Hasinoff et al. - 2010 - Noise-optimal capture for high dynamic range photo.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\M3ZZILHP\\5540167.html:text/html}
}

@article{verkruysse_calibration_2017,
	title = {Calibration of {Contactless} {Pulse} {Oximetry}},
	volume = {124},
	issn = {1526-7598},
	doi = {10.1213/ANE.0000000000001381},
	abstract = {BACKGROUND: Contactless, camera-based photoplethysmography (PPG) interrogates shallower skin layers than conventional contact probes, either transmissive or reflective. This raises questions on the calibratability of camera-based pulse oximetry.
METHODS: We made video recordings of the foreheads of 41 healthy adults at 660 and 840 nm, and remote PPG signals were extracted. Subjects were in normoxic, hypoxic, and low temperature conditions. Ratio-of-ratios were compared to reference SpO2 from 4 contact probes.
RESULTS: A calibration curve based on artifact-free data was determined for a population of 26 individuals. For an SpO2 range of approximately 83\% to 100\% and discarding short-term errors, a root mean square error of 1.15\% was found with an upper 99\% one-sided confidence limit of 1.65\%. Under normoxic conditions, a decrease in ambient temperature from 23 to 7°C resulted in a calibration error of 0.1\% (±1.3\%, 99\% confidence interval) based on measurements for 3 subjects. PPG signal strengths varied strongly among individuals from about 0.9 × 10 to 4.6 × 10 for the infrared wavelength.
CONCLUSIONS: For healthy adults, the results present strong evidence that camera-based contactless pulse oximetry is fundamentally feasible because long-term (eg, 10 minutes) error stemming from variation among individuals expressed as A*rms is significantly lower ({\textless}1.65\%) than that required by the International Organization for Standardization standard ({\textless}4\%) with the notion that short-term errors should be added. A first illustration of such errors has been provided with A**rms = 2.54\% for 40 individuals, including 6 with dark skin. Low signal strength and subject motion present critical challenges that will have to be addressed to make camera-based pulse oximetry practically feasible.},
	language = {eng},
	number = {1},
	journal = {Anesthesia and Analgesia},
	author = {Verkruysse, Wim and Bartula, Marek and Bresch, Erik and Rocque, Mukul and Meftah, Mohammed and Kirenko, Ihor},
	year = {2017},
	pmid = {27258081},
	pmcid = {PMC5145250},
	keywords = {Humans, Photoplethysmography, Reproducibility of Results, Skin, Video Recording, Artifacts, Female, Male, Oximetry, Forehead, Adult, Feasibility Studies, Biomarkers, Calibration, Hypoxia, Oxygen, Predictive Value of Tests, Regional Blood Flow, Time Factors},
	pages = {136--145},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\FRSYD7Y7\\Verkruysse et al. - 2017 - Calibration of Contactless Pulse Oximetry.pdf:application/pdf}
}

@article{patil_mobieye_2020,
	title = {{MobiEye}: turning your smartphones into a ubiquitous unobtrusive vital sign monitoring system},
	volume = {2},
	issn = {2524-5228},
	shorttitle = {{MobiEye}},
	url = {https://doi.org/10.1007/s42486-020-00033-3},
	doi = {10.1007/s42486-020-00033-3},
	abstract = {Recent advances in mobile and wearable technologies have stimulated significantly growing demands for more affordable, user-friendly, pervasive healthcare solutions that can be adopted by the public to proactively manage their health conditions and alleviate the burdens of hospitalization. This study seeks to propose a personalized ubiquitous health monitoring system that can unobtrusively monitor individuals’ vital signs, anywhere at any time. The proposed MobiEye framework makes use of the regular camera available on any smartphones or tablets to record various most important physiological signals without the need for acquiring extra specialized medical devices or attaching any sensor to the body. Through recording the reflected light intensities corresponding to the subtle blood flow changes with blood volume pulses, the proposed technique accurately extracts blood volume pulses from the facial videos recorded in real-world scenarios with the designed protocol. Experiments show that the proposed system achieved \$\$96 {\textbackslash}, {\textbackslash}\% {\textbackslash},\$\$96\%accuracy on average (with the standard deviations of \$\${\textbackslash}pm 1.2\$\$±1.2) for the heart rate estimation and higher correlations between the pulse transit time and the reference systolic blood pressure \$\$(mean {\textbackslash}, r = 0.89,{\textbackslash}, SE= 0.05)\$\$(meanr=0.89,SE=0.05).},
	language = {en},
	number = {2},
	urldate = {2020-10-20},
	journal = {CCF Transactions on Pervasive Computing and Interaction},
	author = {Patil, Omkar and Wang, Wei and Gao, Yang and Jin, Zhanpeng},
	month = jun,
	year = {2020},
	pages = {97--112},
	file = {Springer Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\FVCI4A4B\\Patil et al. - 2020 - MobiEye turning your smartphones into a ubiquitou.pdf:application/pdf}
}

@article{bal_non-contact_2015,
	title = {Non-contact estimation of heart rate and oxygen saturation using ambient light},
	volume = {6},
	copyright = {\&\#169; 2014 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-6-1-86},
	doi = {10.1364/BOE.6.000086},
	abstract = {We propose a robust method for automated computation of heart rate (HR) from digital color video recordings of the human face. In order to extract photoplethysmographic signals, two orthogonal vectors of RGB color space are used. We used a dual tree complex wavelet transform based denoising algorithm to reduce artifacts (e.g. artificial lighting, movement, etc.). Most of the previous work on skin color based HR estimation performed experiments with healthy volunteers and focused to solve motion artifacts. In addition to healthy volunteers we performed experiments with child patients in pediatric intensive care units. In order to investigate the possible factors that affect the non-contact HR monitoring in a clinical environment, we studied the relation between hemoglobin levels and HR estimation errors. Low hemoglobin causes underestimation of HR. Nevertheless, we conclude that our method can provide acceptable accuracy to estimate mean HR of patients in a clinical environment, where the measurements can be performed remotely. In addition to mean heart rate estimation, we performed experiments to estimate oxygen saturation. We observed strong correlations between our SpO2 estimations and the commercial oximeter readings},
	language = {EN},
	number = {1},
	urldate = {2020-10-20},
	journal = {Biomedical Optics Express},
	author = {Bal, Ufuk},
	month = jan,
	year = {2015},
	note = {Publisher: Optical Society of America},
	pages = {86--97},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\KWBUAAYI\\Bal - 2015 - Non-contact estimation of heart rate and oxygen sa.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\7CFNYYTD\\fulltext.html:text/html}
}

@article{verkruysse_remote_2008,
	title = {Remote plethysmographic imaging using ambient light.},
	volume = {16},
	copyright = {\&\#169; 2008 Optical Society of America},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-16-26-21434},
	doi = {10.1364/OE.16.021434},
	abstract = {Plethysmographic signals were measured remotely (\&gt;1m) using ambient light and a simple consumer level digital camera in movie mode. Heart and respiration rates could be quantified up to several harmonics. Although the green channel featuring the strongest plethysmographic signal, corresponding to an absorption peak by (oxy-) hemoglobin, the red and blue channels also contained plethysmographic information. The results show that ambient light photo-plethysmography may be useful for medical purposes such as characterization of vascular skin lesions (e.g., port wine stains) and remote sensing of vital signs (e.g., heart and respiration rates) for triage or sports purposes.},
	language = {EN},
	number = {26},
	urldate = {2020-10-20},
	journal = {Optics Express},
	author = {Verkruysse, Wim and Svaasand, Lars O. and Nelson, J. Stuart},
	month = dec,
	year = {2008},
	note = {Publisher: Optical Society of America},
	pages = {21434--21445},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\DC3ZXEJG\\Verkruysse et al. - 2008 - Remote plethysmographic imaging using ambient ligh.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\4BKG4SZU\\fulltext.html:text/html}
}

@article{gastel_camera-based_2018,
	title = {Camera-based pulse-oximetry - validated risks and opportunities from theoretical analysis},
	volume = {9},
	copyright = {\&\#169; 2017 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-9-1-102},
	doi = {10.1364/BOE.9.000102},
	abstract = {Camera-based pulse-oximetry has recently shown to be feasible, even when the signal is corrupted by noise and motion artifacts. Earlier work showed that using three instead of the common two wavelengths improves robustness of the measurement, however without a thorough investigation on the optimal wavelength selection. We therefore performed a search to identify these wavelengths to further improve the robustness of the measurement. Besides motion, it is empirically known that there are several other factors that influence the measurement leading to falsely-low or falsely-high SpO2 readings. These factors include the presence of dyshemoglobins or other species. In this paper, we use a theoretical skin-model to study how these factors influence the measurement, and how a proper wavelength selection can reduce the impact on the measurement. Additionally, we show that adding a third wavelength does not only improve robustness, but can also be exploited to create a reliability index for the measurement. Finally, we show that the presence of dyshemoglobins in arterial blood can not only be detected but also quantified. We illustrate this by comparing the estimated COHb levels of a small group of smokers and non-smokers, which typically have different CO-levels.},
	language = {EN},
	number = {1},
	urldate = {2020-10-20},
	journal = {Biomedical Optics Express},
	author = {Gastel, Mark Van and Stuijk, Sander and Haan, Gerard De},
	month = jan,
	year = {2018},
	note = {Publisher: Optical Society of America},
	pages = {102--119},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\M6VZS9BD\\Gastel et al. - 2018 - Camera-based pulse-oximetry - validated risks and .pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\T39EEET4\\fulltext.html:text/html}
}

@inproceedings{aubakir_vital_2016,
	title = {Vital sign monitoring utilizing {Eulerian} video magnification and thermography},
	doi = {10.1109/EMBC.2016.7591489},
	abstract = {In this paper we present a proof of concept for non-contact extraction of vital signs using RGB and thermal images obtained from a smart phone. Using our method, heart rate, respiratory rate and forehead temperature can be measured concurrently. Face detection and tracking is leveraged in order to allow natural motion of patients. Heart rate is estimated via processing of visible band RGB video using Eulerian Video Magnification technique. Respiratory rate and the temperature is measured using thermal video. Experiments conducted with 11 healthy subjects indicate that heart rate and respiration rate can be measured with 92 and 94 percent accuracy, respectively.},
	booktitle = {2016 38th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Aubakir, B. and Nurimbetov, B. and Tursynbek, I. and Varol, H. A.},
	month = aug,
	year = {2016},
	note = {ISSN: 1558-4615},
	keywords = {Humans, Algorithms, Cameras, medical image processing, video signal processing, biomedical optical imaging, Face, face recognition, Monitoring, Video Recording, face detection, patient monitoring, cardiology, face tracking, Heart rate, Heart Rate, Motion, Estimation, Female, Male, Forehead, Monitoring, Physiologic, vital sign monitoring, heart rate, Adult, respiratory rate, Young Adult, Temperature measurement, Body Temperature, Thermography, Adolescent, Middle Aged, Respiratory Rate, Smartphone, Thermometry, Eulerian video magnification technique, forehead temperature, infrared imaging, noncontact extraction, RGB images, smart phone, smart phones, temperature measurement, thermal images, thermal video, thermography, visible band RGB video},
	pages = {3527--3530},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\42KAT3IU\\7591489.html:text/html}
}

@inproceedings{alotaibi_biophysical_2017,
	title = {A {Biophysical} {3D} {Morphable} {Model} of {Face} {Appearance}},
	doi = {10.1109/ICCVW.2017.102},
	abstract = {Skin colour forms a curved manifold in RGB space. The variations in skin colour are largely caused by variations in concentration of the pigments melanin and hemoglobin. Hence, linear statistical models of appearance or skin albedo are insufficiently constrained (they can produce implausible skin tones) and lack compactness (they require additional dimensions to linearly approximate a curved manifold). In this paper, we propose to use a biophysical model of skin colouration in order to transform skin colour into a parameter space where linear statistical modelling can take place. Hence, we propose a hybrid of biophysical and statistical modelling. We present a two parameter spectral model of skin colouration, methods for fitting the model to data captured in a lightstage and then build our hybrid model on a sample of such registered data. We present face editing results and compare our model against a pure statistical model built directly on textures.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshops} ({ICCVW})},
	author = {Alotaibi, S. and Smith, W. A. P.},
	month = oct,
	year = {2017},
	note = {ISSN: 2473-9944},
	keywords = {Image color analysis, skin, Skin, Face, face recognition, image colour analysis, statistical analysis, Computational modeling, Solid modeling, Biological system modeling, biophysical 3D morphable model, biophysical model, biophysical modelling, curved manifold, Data models, face appearance, hybrid model, image resolution, image sampling, image texture, implausible skin tones, linear statistical modelling, linear statistical models, parameter spectral model, physiological models, pure statistical model, skin colour forms, skin colouration},
	pages = {824--832},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\JUIPHYDD\\8265311.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\H3FIQJ62\\Alotaibi and Smith - 2017 - A Biophysical 3D Morphable Model of Face Appearanc.pdf:application/pdf}
}

@article{niu_rhythmnet_2020,
	title = {{RhythmNet}: {End}-to-{End} {Heart} {Rate} {Estimation} {From} {Face} via {Spatial}-{Temporal} {Representation}},
	volume = {29},
	issn = {1941-0042},
	shorttitle = {{RhythmNet}},
	doi = {10.1109/TIP.2019.2947204},
	abstract = {Heart rate (HR) is an important physiological signal that reflects the physical and emotional status of a person. Traditional HR measurements usually rely on contact monitors, which may cause inconvenience and discomfort. Recently, some methods have been proposed for remote HR estimation from face videos; however, most of them focus on well-controlled scenarios, their generalization ability into less-constrained scenarios (e.g., with head movement, and bad illumination) are not known. At the same time, lacking large-scale HR databases has limited the use of deep models for remote HR estimation. In this paper, we propose an end-to-end RhythmNet for remote HR estimation from the face. In RyhthmNet, we use a spatial-temporal representation encoding the HR signals from multiple ROI volumes as its input. Then the spatial-temporal representations are fed into a convolutional network for HR estimation. We also take into account the relationship of adjacent HR measurements from a video sequence via Gated Recurrent Unit (GRU) and achieves efficient HR measurement. In addition, we build a large-scale multi-modal HR database (named as VIPL-HR1), which contains 2,378 visible light videos (VIS) and 752 near-infrared (NIR) videos of 107 subjects. Our VIPL-HR database contains various variations such as head movements, illumination variations, and acquisition device changes, replicating a less-constrained scenario for HR estimation. The proposed approach outperforms the state-of-the-art methods on both the public-domain and our VIPL-HR databases.1VIPL-HR is available at: http://vipl.ict.ac.cn/view\_database.php?id=15.},
	journal = {IEEE Transactions on Image Processing},
	author = {Niu, X. and Shan, S. and Han, H. and Chen, X.},
	year = {2020},
	note = {Conference Name: IEEE Transactions on Image Processing},
	keywords = {Image color analysis, Skin, Head, image motion analysis, medical image processing, video signal processing, face recognition, cardiology, convolutional neural nets, Heart rate, image sequences, face videos, Estimation, Databases, rPPG, biomedical measurement, infrared imaging, convolutional network, emotional status, end-to-end heart rate estimation, end-to-end learning, gated recurrent unit, head movement, HR measurement, image representation, large-scale HR databases, near-infrared videos, physical status, physiological signal, recurrent neural nets, Remote heart rate estimation, remote HR estimation, RhythmNet, ROI volumes, spatial-temporal representation, video sequence, VIPL-HR databases, visible light videos, Webcams},
	pages = {2409--2423},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\FV763TTS\\8879658.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\GJZADINE\\Niu et al. - 2020 - RhythmNet End-to-End Heart Rate Estimation From F.pdf:application/pdf}
}

@article{po_block-based_2018,
	title = {Block-based adaptive {ROI} for remote photoplethysmography},
	volume = {77},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-017-4563-7},
	doi = {10.1007/s11042-017-4563-7},
	abstract = {Remote photoplethysmography (rPPG) can achieve contactless human vital signs monitoring, but its signal quality is limited by the remote operation nature. In practical applications, improving the rPPG signal quality becomes an essential task. As a remote imaging technique, rPPG utilizes a camera to capture a video of a skin area, especially the facial area, then focuses on a particular sub-area as the region of interest (ROI). In this paper, we investigated a novel adaptive ROI (AROI) approach for improving the rPPG signal quality. In this approach, block-based spatial-temporal division is performed on a captured face video. Based on these segmented video pipelines, the spatial-temporal quality distribution of the rPPG signals is estimated using a signal-to-noise ratio (SNR) feature. Afterwards, AROIs are calculated through mean-shift clustering and adaptive thresholding in SNR maps. As the AROI can be dynamically adjusted according to the spatial-temporal quality distribution of rPPG signals on the face, the quality of the final recovered rPPG signal is improved. The performance of the proposed AROI approach was evaluated with both still and moving subjects. Compared to conventional ROI methods for rPPG, the proposed AROI obtained a higher accuracy in heart rate measurement. And the state-of-the-art motion-resistant rPPG techniques can be effectively enhanced through being integrated with the AROI.},
	language = {en},
	number = {6},
	urldate = {2020-10-21},
	journal = {Multimedia Tools and Applications},
	author = {Po, Lai-Man and Feng, Litong and Li, Yuming and Xu, Xuyuan and Cheung, Terence Chun-Ho and Cheung, Kwok-Wai},
	month = mar,
	year = {2018},
	pages = {6503--6529},
	file = {Springer Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\DFXR348X\\Po et al. - 2018 - Block-based adaptive ROI for remote photoplethysmo.pdf:application/pdf}
}

@article{annis_rapid_2020,
	title = {Rapid implementation of a {COVID}-19 remote patient monitoring program},
	volume = {27},
	url = {https://academic.oup.com/jamia/article/27/8/1326/5835871},
	doi = {10.1093/jamia/ocaa097},
	abstract = {AbstractObjective.  The study sought to evaluate early lessons from a remote patient monitoring engagement and education technology solution for patients with c},
	language = {en},
	number = {8},
	urldate = {2020-10-23},
	journal = {Journal of the American Medical Informatics Association},
	author = {Annis, Tucker and Pleasants, Susan and Hultman, Gretchen and Lindemann, Elizabeth and Thompson, Joshua A. and Billecke, Stephanie and Badlani, Sameer and Melton, Genevieve B.},
	month = aug,
	year = {2020},
	note = {Publisher: Oxford Academic},
	pages = {1326--1330},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\SG4RFNY9\\Annis et al. - 2020 - Rapid implementation of a COVID-19 remote patient .pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\2XECFQTT\\5835871.html:text/html}
}

@article{ford_leveraging_2020,
	title = {Leveraging health system telehealth and informatics infrastructure to create a continuum of services for {COVID}-19 screening, testing, and treatment},
	volume = {27},
	url = {https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaa157/5865271},
	doi = {10.1093/jamia/ocaa157},
	abstract = {AbstractObjectives.  We describe our approach in using health information technology to provide a continuum of services during the coronavirus disease 2019 (COV},
	language = {en},
	number = {12},
	urldate = {2020-10-23},
	journal = {Journal of the American Medical Informatics Association},
	author = {Ford, Dee and Harvey, Jillian B. and McElligott, James and King, Kathryn and Simpson, Kit N. and Valenta, Shawn and Warr, Emily H. and Walsh, Tasia and Debenham, Ellen and Teasdale, Carla and Meystre, Stephane and Obeid, Jihad S. and Metts, Christopher and Lenert, Leslie A.},
	month = dec,
	year = {2020},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\F7752HXB\\Ford et al. - Leveraging health system telehealth and informatic.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\I2F6EQ5I\\5865271.html:text/html}
}

@article{fitzpatrick_validity_1988,
	title = {The {Validity} and {Practicality} of {Sun}-{Reactive} {Skin} {Types} {I} {Through} {VI}},
	volume = {124},
	issn = {0003-987X},
	url = {https://jamanetwork.com/journals/jamadermatology/fullarticle/549509},
	doi = {10.1001/archderm.1988.01670060015008},
	abstract = {{\textless}p{\textgreater}The concept of sun-reactive "skin typing" was created in 1975$^{\textrm{1}}$for a specific need: to be able to classify persons\textit{with white skin}in order to select the correct initial doses of ultraviolet A (UVA) (in joules per cubic centimeter) in the application of the then newly developed technique for the treatment of psoriasis—oral methoxsalen photochemotherapy (PUVA).$^{\textrm{2}}$The need arose as a result of experience with several patients who were a "dark" phenotype (brown or even black hair, and some with brown eyes) but, to our surprise, developed severe phototoxic reactions following oral ingestion of 0.6 mg/kg of methoxsalen and then, two hours later, were exposed to 4 to 6 J/cm$^{\textrm{2}}$. These initial doses were obviously too high, and it was then understood that the estimation of the white-skinned person's tolerance level to oral PUVA could not be based solely on the phenotype (hair and eye color).{\textless}/p{\textgreater}},
	language = {en},
	number = {6},
	urldate = {2020-10-23},
	journal = {Archives of Dermatology},
	author = {Fitzpatrick, Thomas B.},
	month = jun,
	year = {1988},
	note = {Publisher: American Medical Association},
	pages = {869--871},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\IFNV9MJY\\549509.html:text/html}
}

@inproceedings{yang_real-time_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Real-{Time} {Specular} {Highlight} {Removal} {Using} {Bilateral} {Filtering}},
	isbn = {978-3-642-15561-1},
	doi = {10.1007/978-3-642-15561-1_7},
	abstract = {In this paper, we propose a simple but effective specular highlight removal method using a single input image. Our method is based on a key observation - the maximum fraction of the diffuse color component (so called maximum diffuse chromaticity in the literature) in local patches in color images changes smoothly. Using this property, we can estimate the maximum diffuse chromaticity values of the specular pixels by directly applying low-pass filter to the maximum fraction of the color components of the original image, such that the maximum diffuse chromaticity values can be propagated from the diffuse pixels to the specular pixels. The diffuse color at each pixel can then be computed as a nonlinear function of the estimated maximum diffuse chromaticity. Our method can be directly extended for multi-color surfaces if edge-preserving filters (e.g., bilateral filter) are used such that the smoothing can be guided by the maximum diffuse chromaticity. But maximum diffuse chromaticity is to be estimated. We thus present an approximation and demonstrate its effectiveness. Recent development in fast bilateral filtering techniques enables our method to run over 200× faster than the state-of-the-art on a standard CPU and differentiates our method from previous work.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2010},
	publisher = {Springer},
	author = {Yang, Qingxiong and Wang, Shengnan and Ahuja, Narendra},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	year = {2010},
	pages = {87--100},
	file = {Springer Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\QKAGBLBC\\Yang et al. - 2010 - Real-Time Specular Highlight Removal Using Bilater.pdf:application/pdf}
}

@inproceedings{balakrishnan_detecting_2013,
	title = {Detecting {Pulse} from {Head} {Motions} in {Video}},
	doi = {10.1109/CVPR.2013.440},
	abstract = {We extract heart rate and beat lengths from videos by measuring subtle head motion caused by the Newtonian reaction to the influx of blood at each beat. Our method tracks features on the head and performs principal component analysis (PCA) to decompose their trajectories into a set of component motions. It then chooses the component that best corresponds to heartbeats based on its temporal frequency spectrum. Finally, we analyze the motion projected to this component and identify peaks of the trajectories, which correspond to heartbeats. When evaluated on 18 subjects, our approach reported heart rates nearly identical to an electrocardiogram device. Additionally we were able to capture clinically relevant information about heart rate variability.},
	booktitle = {2013 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Balakrishnan, G. and Durand, F. and Guttag, J.},
	month = jun,
	year = {2013},
	note = {ISSN: 1063-6919},
	keywords = {feature extraction, beat lengths, blood, blood influx, electrocardiogram device, electrocardiography, Electrocardiography, Feature extraction, Head, heart rate extraction, heart rate variability, Heart rate variability, humans, image motion analysis, medical image processing, medical imaging, motion estimation, Newtonian reaction, object detection, optical flow, PCA, principal component analysis, Principal component analysis, pulse detection, pulse measurement, subtle head motion measurement, temporal frequency spectrum, Trajectory, video signal processing},
	pages = {3430--3437},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\FN799WN6\\Balakrishnan et al. - 2013 - Detecting Pulse from Head Motions in Video.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\2EECJSZB\\6619284.html:text/html}
}

@inproceedings{nowara_sparseppg_2018,
	title = {{SparsePPG}: {Towards} {Driver} {Monitoring} {Using} {Camera}-{Based} {Vital} {Signs} {Estimation} in {Near}-{Infrared}},
	shorttitle = {{SparsePPG}},
	doi = {10.1109/CVPRW.2018.00174},
	abstract = {Camera-based measurement of the heartbeat signal from minute changes in the appearance of a person's skin is known as remote photoplethysmography (rPPG). Methods for rPPG have improved considerably in recent years, making possible its integration into applications such as telemedicine. Driver monitoring using in-car cameras is another potential application of this emerging technology. Unfortunately, there are several challenges unique to the driver monitoring context that must be overcome. First, there are drastic illumination changes on the driver's face, both during the day (as sun filters in and out of overhead trees, etc.) and at night (from streetlamps and oncoming headlights), which current rPPG algorithms cannot account for. We argue that these variations are significantly reduced by narrow-bandwidth near-infrared (NIR) active illumination at 940 nm, with matching bandpass filter on the camera. Second, the amount of motion during driving is significant. We perform a preliminary analysis of the motion magnitude and argue that any in-car solution must provide better robustness to motion artifacts. Third, low signal-to-noise ratio (SNR) and false peaks due to motion have the potential to confound the rPPG signal. To address these challenges, we develop a novel rPPG signal tracking and denoising algorithm (sparsePPG) based on Robust Principal Components Analysis and sparse frequency spectrum estimation. We release a new dataset of face videos collected simultaneously in RGB and NIR.We demonstrate that in each of these frequency ranges, our new method performs as well as or better than current state-of-the-art rPPG algorithms. Overall, our preliminary study indicates that while driver vital signs monitoring using cameras is promising, much work needs to be done in terms of improving robustness to motion artifacts before it becomes practical.},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	author = {Nowara, E. M. and Marks, T. K. and Mansour, H. and Veeraraghavan, A.},
	month = jun,
	year = {2018},
	note = {ISSN: 2160-7516},
	keywords = {medical signal processing, photoplethysmography, remote photoplethysmography, skin, principal component analysis, video signal processing, cameras, patient monitoring, band-pass filters, camera-based measurement, camera-based vital sign estimation, Computer vision, Conferences, driver monitoring, driver vital signs, face videos, false peaks, heartbeat signal, in-car cameras, in-car solution, matching bandpass filter, motion artifacts, motion magnitude, narrow-bandwidth near-infrared active illumination, oncoming headlights, overhead trees, Pattern recognition, person skin, preliminary analysis, Robust Principal Components Analysis, rPPG signal tracking, signal-to-noise ratio, sparse frequency spectrum estimation, sparsePPG, sun filters, video cameras, wavelength 940.0 nm},
	pages = {1353--135309},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\D4K3WLMS\\8575330.html:text/html}
}

@inproceedings{kazemi_one_2014,
	title = {One millisecond face alignment with an ensemble of regression trees},
	doi = {10.1109/CVPR.2014.241},
	abstract = {This paper addresses the problem of Face Alignment for a single image. We show how an ensemble of regression trees can be used to estimate the face's landmark positions directly from a sparse subset of pixel intensities, achieving super-realtime performance with high quality predictions. We present a general framework based on gradient boosting for learning an ensemble of regression trees that optimizes the sum of square error loss and naturally handles missing or partially labelled data. We show how using appropriate priors exploiting the structure of image data helps with efficient feature selection. Different regularization strategies and its importance to combat overfitting are also investigated. In addition, we analyse the effect of the quantity of training data on the accuracy of the predictions and explore the effect of data augmentation using synthesized data.},
	booktitle = {2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Kazemi, V. and Sullivan, J.},
	month = jun,
	year = {2014},
	note = {ISSN: 1063-6919},
	keywords = {Face, face recognition, Training, learning (artificial intelligence), regression analysis, pose estimation, feature selection, face alignment, Boosting, data augmentation, Decision Trees, Face Alignment, face landmark position estimation, gradient boosting, Gradient Boosting, gradient methods, optimisation, overfitting, pixel intensities, Real-Time, Regression tree analysis, regression tree ensemble, regularization strategies, Shape, square error loss sum optimization, time 1 ms, Training data, trees (mathematics), Vectors},
	pages = {1867--1874},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\XC96RXMN\\6909637.html:text/html;Submitted Version:C\:\\Users\\krish\\Zotero\\storage\\4R8HAY3C\\Kazemi and Sullivan - 2014 - One millisecond face alignment with an ensemble of.pdf:application/pdf}
}

@inproceedings{lewandowska_measuring_2011,
	title = {Measuring pulse rate with a webcam — {A} non-contact method for evaluating cardiac activity},
	abstract = {In this paper the simple and robust method of measuring the pulse rate is presented. Elaborated algorithm allows for efficient pulse rate registration directly from face image captured from webcam. The desired signal was obtained by proper channel selection and principal component analysis. A developed non-contact method of heart rate monitoring is shown in the paper. The proposed technique may have a great value in monitoring person at home after adequate enhancements are introduced.},
	booktitle = {2011 {Federated} {Conference} on {Computer} {Science} and {Information} {Systems} ({FedCSIS})},
	author = {Lewandowska, M. and Rumiński, J. and Kocejko, T. and Nowak, J.},
	month = sep,
	year = {2011},
	keywords = {Image color analysis, Electrocardiography, medical image processing, principal component analysis, Principal component analysis, cameras, Face, face recognition, cardiology, Heart rate, Pulse measurements, Forehead, heart rate monitoring, cardiac activity evaluation, channel selection, face image, pulse rate measurement, pulse rate registration, Webcam},
	pages = {405--410},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\DDZTIZLW\\6078233.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\JLYTEQF3\\Lewandowska et al. - 2011 - Measuring pulse rate with a webcam — A non-contact.pdf:application/pdf}
}

@article{nowara_benefit_2020,
	title = {The {Benefit} of {Distraction}: {Denoising} {Remote} {Vitals} {Measurements} using {Inverse} {Attention}},
	shorttitle = {The {Benefit} of {Distraction}},
	url = {http://arxiv.org/abs/2010.07770},
	abstract = {Attention is a powerful concept in computer vision. End-to-end networks that learn to focus selectively on regions of an image or video often perform strongly. However, other image regions, while not necessarily containing the signal of interest, may contain useful context. We present an approach that exploits the idea that statistics of noise may be shared between the regions that contain the signal of interest and those that do not. Our technique uses the inverse of an attention mask to generate a noise estimate that is then used to denoise temporal observations. We apply this to the task of camera-based physiological measurement. A convolutional attention network is used to learn which regions of a video contain the physiological signal and generate a preliminary estimate. A noise estimate is obtained by using the pixel intensities in the inverse regions of the learned attention mask, this in turn is used to refine the estimate of the physiological signal. We perform experiments on two large benchmark datasets and show that this approach produces state-of-the-art results, increasing the signal-to-noise ratio by up to 5.8 dB, reducing heart rate and breathing rate estimation error by as much as 30\%, recovering subtle pulse waveform dynamics, and generalizing from RGB to NIR videos without retraining.},
	urldate = {2020-10-23},
	journal = {arXiv:2010.07770 [cs, eess]},
	author = {Nowara, Ewa and McDuff, Daniel and Veeraraghavan, Ashok},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.07770},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\krish\\Zotero\\storage\\PGB9CNHN\\Nowara et al. - 2020 - The Benefit of Distraction Denoising Remote Vital.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\krish\\Zotero\\storage\\5MSKFP5V\\2010.html:text/html}
}

@inproceedings{nagamatsu_ppg3d_2020,
	title = {{PPG3D}: {Does} {3D} head tracking improve camera-based {PPG} estimation?},
	shorttitle = {{PPG3D}},
	doi = {10.1109/EMBC44109.2020.9176065},
	abstract = {Over the last few years, camera-based estimation of vital signs referred to as imaging photoplethysmography (iPPG) has garnered significant attention due to the relative simplicity, ease, unobtrusiveness and flexibility offered by such measurements. It is expected that iPPG may be integrated into a host of emerging applications in areas as diverse as autonomous cars, neonatal monitoring, and telemedicine. In spite of this potential, the primary challenge of non-contact camera-based measurements is the relative motion between the camera and the subjects. Current techniques employ 2D feature tracking to reduce the effect of subject and camera motion but they are limited to handling translational and in-plane motion. In this paper, we study, for the first-time, the utility of 3D face tracking to allow iPPG to retain robust performance even in presence of out-of-plane and large relative motions. We use a RGB-D camera to obtain 3D information from the subjects and use the spatial and depth information to fit a 3D face model and track the model over the video frames. This allows us to estimate correspondence over the entire video with pixel-level accuracy, even in the presence of out-of-plane or large motions. We then estimate iPPG from the warped video data that ensures per-pixel correspondence over the entire window-length used for estimation. Our experiments demonstrate improvement in robustness when head motion is large.},
	booktitle = {2020 42nd {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} {Biology} {Society} ({EMBC})},
	author = {Nagamatsu, G. and Nowara, E. M. and Pai, A. and Veeraraghavan, A. and Kawasaki, H.},
	month = jul,
	year = {2020},
	note = {ISSN: 2694-0604},
	keywords = {Cameras, feature extraction, photoplethysmography, image motion analysis, medical image processing, motion estimation, video signal processing, biomedical optical imaging, cameras, Face, face recognition, Tracking, patient monitoring, Heart rate, vital signs, imaging photoplethysmography, telemedicine, Three-dimensional displays, Two dimensional displays, 2D feature tracking, 3D face model, camera-based PPG estimation, head motion, in-plane motion, iPPG, neonatal monitoring, noncontact camera-based measurements, PPG3D, RGB-D camera, Task analysis},
	pages = {1194--1197},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\NZ8F8Q9Y\\Nagamatsu et al. - 2020 - PPG3D Does 3D head tracking improve camera-based .pdf:application/pdf}
}

@article{karippacheril_data_2013,
	title = {Data acquisition from {S}/5 {GE} {Datex} anesthesia monitor using {VSCapture}: {An} open source.{NET}/{Mono} tool},
	volume = {29},
	issn = {0970-9185},
	shorttitle = {Data acquisition from {S}/5 {GE} {Datex} anesthesia monitor using {VSCapture}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3788264/},
	doi = {10.4103/0970-9185.117096},
	number = {3},
	urldate = {2020-11-11},
	journal = {Journal of Anaesthesiology, Clinical Pharmacology},
	author = {Karippacheril, John George and Ho, Tam Yuk},
	year = {2013},
	pmid = {24106390},
	pmcid = {PMC3788264},
	pages = {423--424}
}

@article{altman_measurement_1983,
	title = {Measurement in {Medicine}: {The} {Analysis} of {Method} {Comparison} {Studies}},
	volume = {32},
	issn = {0039-0526},
	shorttitle = {Measurement in {Medicine}},
	url = {https://www.jstor.org/stable/2987937},
	doi = {10.2307/2987937},
	abstract = {Methods of analysis used in the comparison of two methods of measurement are reviewed. The use of correlation, regression and the difference between means is criticized. A simple parametric approach is proposed based on analysis of variance and simple graphical methods.},
	number = {3},
	urldate = {2020-11-11},
	journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
	author = {Altman, D. G. and Bland, J. M.},
	year = {1983},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {307--317},
	file = {Submitted Version:C\:\\Users\\krish\\Zotero\\storage\\JT4SIRYP\\Altman and Bland - 1983 - Measurement in Medicine The Analysis of Method Co.pdf:application/pdf}
}

@article{gu_characteristics_2020,
	title = {Characteristics {Associated} {With} {Racial}/{Ethnic} {Disparities} in {COVID}-19 {Outcomes} in an {Academic} {Health} {Care} {System}},
	volume = {3},
	issn = {2574-3805},
	doi = {10.1001/jamanetworkopen.2020.25197},
	abstract = {Importance: Black patients are overrepresented in the number of COVID-19 infections, hospitalizations, and deaths in the US. Reasons for this disparity may be due to underlying comorbidities or sociodemographic factors that require further exploration.
Objective: To systematically determine patient characteristics associated with racial/ethnic disparities in COVID-19 outcomes.
Design, Setting, and Participants: This retrospective cohort study used comparative groups of patients tested or treated for COVID-19 at the University of Michigan from March 10, 2020, to April 22, 2020, with an outcome update through July 28, 2020. A group of randomly selected untested individuals were included for comparison. Examined factors included race/ethnicity, age, smoking, alcohol consumption, comorbidities, body mass index (BMI; calculated as weight in kilograms divided by height in meters squared), and residential-level socioeconomic characteristics.
Exposure: In-house polymerase chain reaction (PCR) tests, commercial antibody tests, nasopharynx or oropharynx PCR deployed by the Michigan Department of Health and Human Services and reverse transcription-PCR tests performed in external labs.
Main Outcomes and Measures: The main outcomes were being tested for COVID-19, having test results positive for COVID-19 or being diagnosed with COVID-19, being hospitalized for COVID-19, requiring intensive care unit (ICU) admission for COVID-19, and COVID-19-related mortality (including inpatient and outpatient). Medical comorbidities were defined from the International Classification of Diseases, Ninth Revision, and International Classification of Diseases, Tenth Revision, codes and were aggregated into a comorbidity score. Associations with COVID-19 outcomes were examined using odds ratios (ORs).
Results: Of 5698 patients tested for COVID-19 (mean [SD] age, 47.4 [20.9] years; 2167 [38.0\%] men; mean [SD] BMI, 30.0 [8.0]), most were non-Hispanic White (3740 patients [65.6\%]) or non-Hispanic Black (1058 patients [18.6\%]). The comparison group included 7168 individuals who were not tested (mean [SD] age, 43.1 [24.1] years; 3257 [45.4\%] men; mean [SD] BMI, 28.5 [7.1]). Among 1139 patients diagnosed with COVID-19, 492 (43.2\%) were White and 442 (38.8\%) were Black; 523 (45.9\%) were hospitalized, 283 (24.7\%) were admitted to the ICU, and 88 (7.7\%) died. Adjusting for age, sex, socioeconomic status, and comorbidity score, Black patients were more likely to be hospitalized compared with White patients (OR, 1.72 [95\% CI, 1.15-2.58]; P = .009). In addition to older age, male sex, and obesity, living in densely populated areas was associated with increased risk of hospitalization (OR, 1.10 [95\% CI, 1.01-1.19]; P = .02). In the overall population, higher risk of hospitalization was also observed in patients with preexisting type 2 diabetes (OR, 1.82 [95\% CI, 1.25-2.64]; P = .02) and kidney disease (OR, 2.87 [95\% CI, 1.87-4.42]; P {\textless} .001). Compared with White patients, obesity was associated with higher risk of having test results positive for COVID-19 among Black patients (White: OR, 1.37 [95\% CI, 1.01-1.84]; P = .04. Black: OR, 3.11 [95\% CI, 1.64-5.90]; P {\textless} .001; P for interaction = .02). Having any cancer was associated with higher risk of positive COVID-19 test results for Black patients (OR, 1.82 [95\% CI, 1.19-2.78]; P = .005) but not White patients (OR, 1.08 [95\% CI, 0.84-1.40]; P = .53; P for interaction = .04). Overall comorbidity burden was associated with higher risk of hospitalization in White patients (OR, 1.30 [95\% CI, 1.11-1.53]; P = .001) but not in Black patients (OR, 0.99 [95\% CI, 0.83-1.17]; P = .88; P for interaction = .02), as was type 2 diabetes (White: OR, 2.59 [95\% CI, 1.49-4.48]; P {\textless} .001; Black: OR, 1.17 [95\% CI, 0.66-2.06]; P = .59; P for interaction = .046). No statistically significant racial differences were found in ICU admission and mortality based on adjusted analysis.
Conclusions and Relevance: These findings suggest that preexisting type 2 diabetes or kidney diseases and living in high-population density areas were associated with higher risk for COVID-19 hospitalization. Associations of risk factors with COVID-19 outcomes differed by race.},
	language = {eng},
	number = {10},
	journal = {JAMA network open},
	author = {Gu, Tian and Mack, Jasmine A. and Salvatore, Maxwell and Prabhu Sankar, Swaraaj and Valley, Thomas S. and Singh, Karandeep and Nallamothu, Brahmajee K. and Kheterpal, Sachin and Lisabeth, Lynda and Fritsche, Lars G. and Mukherjee, Bhramar},
	year = {2020},
	pmid = {33084902},
	pmcid = {PMC7578774},
	keywords = {Humans, Female, Male, Adult, Intensive Care Units, Middle Aged, African Americans, Aged, Betacoronavirus, Comorbidity, Coronavirus Infections, Diabetes Mellitus, Type 2, European Continental Ancestry Group, Health Status Disparities, Hospitalization, Kidney Diseases, Michigan, Neoplasms, Obesity, Odds Ratio, Pandemics, Pneumonia, Viral, Population Density, Retrospective Studies, Risk Factors},
	pages = {e2025197},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\8W8XEHVF\\Gu et al. - 2020 - Characteristics Associated With RacialEthnic Disp.pdf:application/pdf}
}

@article{holtgrave_assessing_2020,
	title = {Assessing racial and ethnic disparities using a {COVID}-19 outcomes continuum for {New} {York} {State}},
	volume = {48},
	issn = {1047-2797},
	url = {http://www.sciencedirect.com/science/article/pii/S1047279720302076},
	doi = {10.1016/j.annepidem.2020.06.010},
	abstract = {Purpose
Heightened COVID-19 mortality among Black non-Hispanic and Hispanic communities (relative to white non-Hispanic) is well established. This study aims to estimate the relative contributions to fatality disparities in terms of differences in SARS-CoV-2 infections, diagnoses, and disease severity.
Methods
We constructed COVID-19 outcome continua (similar to the HIV care continuum) for white non-Hispanic, Black non-Hispanic, and Hispanic adults in New York State. For each stage in the COVID-19 outcome continua (population, infection experience, diagnosis, hospitalization, fatality), we synthesized the most recent publicly available data. We described each continuum using overall percentages, fatality rates, and relative changes between stages, with comparisons between race and ethnicity using risk ratios.
Results
Estimated per-population COVID-19 fatality rates were 0.03\%, 0.18\%, and 0.12\% for white non-Hispanic, Black non-Hispanic, and Hispanic adults, respectively. The 3.48-fold disparity for Hispanic, relative to white, communities was explained by differences in infection experience, whereas the 5.38-fold disparity for non-Hispanic Black, relative to white, communities was primarily driven by differences in both infection experience and in the need for hospitalization, given infection.
Conclusions
These findings suggest the most impactful stages on which to intervene with programs and policies to build COVID-19 health equity.},
	language = {en},
	urldate = {2020-11-10},
	journal = {Annals of Epidemiology},
	author = {Holtgrave, David R. and Barranco, Meredith A. and Tesoriero, James M. and Blog, Debra S. and Rosenberg, Eli S.},
	month = aug,
	year = {2020},
	keywords = {Coronavirus, Epidemics, Epidemiology, Infectious diseases, Race factors, Surveillance},
	pages = {9--14},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\HD7IKCRY\\Holtgrave et al. - 2020 - Assessing racial and ethnic disparities using a CO.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\krish\\Zotero\\storage\\4REDXHJG\\S1047279720302076.html:text/html}
}

@article{azar_disparities_2020,
	title = {Disparities {In} {Outcomes} {Among} {COVID}-19 {Patients} {In} {A} {Large} {Health} {Care} {System} {In} {California}},
	volume = {39},
	issn = {0278-2715},
	url = {https://www.healthaffairs.org/doi/10.1377/hlthaff.2020.00598},
	doi = {10.1377/hlthaff.2020.00598},
	abstract = {As the novel coronavirus disease (COVID-19) pandemic spreads throughout the United States, evidence is mounting that racial and ethnic minorities and socioeconomically disadvantaged groups are bearing a disproportionate burden of illness and death. We conducted a retrospective cohort analysis of COVID-19 patients at Sutter Health, a large integrated health system in northern California, to measure potential disparities. We used Sutter’s integrated electronic health record to identify adults with suspected and confirmed COVID-19, and we used multivariable logistic regression to assess risk of hospitalization, adjusting for known risk factors, such as race/ethnicity, sex, age, health, and socioeconomic variables. We analyzed 1,052 confirmed cases of COVID-19 from the period January 1–April 8, 2020. Among our findings, we observed that compared with non-Hispanic white patients, non-Hispanic African American patients had 2.7 times the odds of hospitalization, after adjustment for age, sex, comorbidities, and income. We explore possible explanations for this, including societal factors that either result in barriers to timely access to care or create circumstances in which patients view delaying care as the most sensible option. Our study provides real-world evidence of racial and ethnic disparities in the presentation of COVID-19.},
	number = {7},
	urldate = {2020-11-10},
	journal = {Health Affairs},
	author = {Azar, Kristen M. J. and Shen, Zijun and Romanelli, Robert J. and Lockhart, Stephen H. and Smits, Kelly and Robinson, Sarah and Brown, Stephanie and Pressman, Alice R.},
	month = may,
	year = {2020},
	note = {Publisher: Health Affairs},
	pages = {1253--1262},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\6EVF75F4\\Azar et al. - 2020 - Disparities In Outcomes Among COVID-19 Patients In.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\CS9NNY9K\\hlthaff.2020.html:text/html}
}

@article{abedi_racial_2020,
	title = {Racial, {Economic}, and {Health} {Inequality} and {COVID}-19 {Infection} in the {United} {States}},
	issn = {2196-8837},
	doi = {10.1007/s40615-020-00833-4},
	abstract = {OBJECTIVES: There is preliminary evidence of racial and social economic disparities in the population infected by and dying from COVID-19. The goal of this study is to report the associations of COVID-19 with respect to race, health, and economic inequality in the United States.
METHODS: We performed an ecological study of the associations between infection and mortality rate of COVID-19 and demographic, socioeconomic, and mobility variables from 369 counties (total population, 102,178,117 [median, 73,447; IQR, 30,761-256,098]) from the seven most affected states (Michigan, New York, New Jersey, Pennsylvania, California, Louisiana, Massachusetts).
RESULTS: The risk factors for infection and mortality are different. Our analysis shows that counties with more diverse demographics, higher population, education, income levels, and lower disability rates were at a higher risk of COVID-19 infection. However, counties with higher proportion with disability and poverty rates had a higher death rate. African Americans were more vulnerable to COVID-19 than other ethnic groups (1981 African American infected cases versus 658 Whites per million). Data on mobility changes corroborate the impact of social distancing.
CONCLUSION: Our study provides evidence of racial, economic, and health inequality in the population infected by and dying from COVID-19. These observations might be due to the workforce of essential services, poverty, and access to care. Counties in more urban areas are probably better equipped at providing care. The lower rate of infection, but a higher death rate in counties with higher poverty and disability could be due to lower levels of mobility, but a higher rate of comorbidities and health care access.},
	language = {eng},
	journal = {Journal of Racial and Ethnic Health Disparities},
	author = {Abedi, Vida and Olulana, Oluwaseyi and Avula, Venkatesh and Chaudhary, Durgesh and Khan, Ayesha and Shahjouei, Shima and Li, Jiang and Zand, Ramin},
	month = sep,
	year = {2020},
	pmid = {32875535},
	pmcid = {PMC7462354},
	keywords = {COVID-19, Ecological-based study, Economic inequality, Health status disparities, Healthcare disparities, Population-based analysis, Racial disparity, Socioeconomic factors, United States},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\HQ9VSJ9B\\Abedi et al. - 2020 - Racial, Economic, and Health Inequality and COVID-.pdf:application/pdf}
}

@article{connolly_rapid_2020,
	title = {Rapid {Increase} in {Telemental} {Health} {Within} the {Department} of {Veterans} {Affairs} {During} the {COVID}-19 {Pandemic}},
	issn = {1530-5627},
	url = {https://www.liebertpub.com/doi/10.1089/TMJ.2020.0233},
	doi = {10.1089/tmj.2020.0233},
	abstract = {Background: The use of telemental health via videoconferencing (TMH-V) became critical during the Coronavirus disease 2019 (COVID-19) pandemic due to restriction of non-urgent in-person appointments. The current brief report demonstrates the rapid growth in TMH-V appointments in the weeks following the pandemic declaration within the Department of Veterans Affairs (VA), the largest healthcare system in the United States.Methods: COVID-19 changes in TMH-V appointments were captured during the six weeks following the World Health Organization's pandemic declaration (March 11, 2020-April 22, 2020). Pre-COVID-19 TMH-V encounters were assessed from October 1, 2017 to March 10, 2020.Results: Daily TMH-V encounters rose from 1,739 on March 11 to 11,406 on April 22 (556\% growth, 222,349 total encounters). Between March 11-April 22, 114,714 patients were seen via TMH-V, and 77.5\% were first-time TMH-V users. 12,342 MH providers completed a TMH-V appointment between March 11-April 22, and 34.7\% were first-time TMH-V users. The percentage growth of TMH-V appointments was higher than the rise in telephone appointments (442\% growth); in-person appointments dropped by 81\% during this time period.Discussion and Conclusions: The speed of VA's growth in TMH-V appointments in the wake of the COVID-19 pandemic was facilitated by its pre-existing telehealth infrastructure, including earlier national efforts to increase the number of providers using TMH-V. Longstanding barriers to TMH-V implementation were lessened in the context of a pandemic, during which non-urgent in-person MH care was drastically reduced. Future work is necessary to understand the extent to which COVID-19 related changes in TMH-V use may permanently impact mental health care provision.},
	urldate = {2020-11-10},
	journal = {Telemedicine and e-Health},
	author = {Connolly, Samantha L. and Stolzmann, Kelly L. and Heyworth, Leonie and Weaver, Kendra R. and Bauer, Mark S. and Miller, Christopher J.},
	month = sep,
	year = {2020},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\G4FE5E35\\Connolly et al. - 2020 - Rapid Increase in Telemental Health Within the Dep.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\HFPKG8BM\\TMJ.2020.html:text/html}
}

@article{jm_virtual_2020,
	title = {Virtual {Care} {Expansion} in the {Veterans} {Health} {Administration} {During} the {COVID}-19 {Pandemic}: {Clinical} {Services} and {Patient} {Characteristics} {Associated} with {Utilization}.},
	issn = {1067-5027, 1527-974X},
	shorttitle = {Virtual {Care} {Expansion} in the {Veterans} {Health} {Administration} {During} the {COVID}-19 {Pandemic}},
	url = {https://europepmc.org/article/med/33125032},
	doi = {10.1093/jamia/ocaa284},
	abstract = {Europe PMC is an archive of life sciences journal literature., Virtual Care Expansion in the Veterans Health Administration During the COVID-19 Pandemic: Clinical Services and Patient Characteristics Associated with Utilization.},
	language = {English},
	urldate = {2020-11-10},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Jm, Ferguson and J, Jacobs and M, Yefimova and L, Greene and L, Heyworth and Dm, Zulman},
	month = oct,
	year = {2020},
	pmid = {33125032},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\TYW9FT9R\\33125032.html:text/html}
}

@article{cahan_putting_2019,
	title = {Putting the data before the algorithm in big data addressing personalized healthcare},
	volume = {2},
	copyright = {2019 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-019-0157-2},
	doi = {10.1038/s41746-019-0157-2},
	abstract = {Technologies leveraging big data, including predictive algorithms and machine learning, are playing an increasingly important role in the delivery of healthcare. However, evidence indicates that such algorithms have the potential to worsen disparities currently intrinsic to the contemporary healthcare system, including racial biases. Blame for these deficiencies has often been placed on the algorithm—but the underlying training data bears greater responsibility for these errors, as biased outputs are inexorably produced by biased inputs. The utility, equity, and generalizability of predictive models depend on population-representative training data with robust feature sets. So while the conventional paradigm of big data is deductive in nature—clinical decision support—a future model harnesses the potential of big data for inductive reasoning. This may be conceptualized as clinical decision questioning, intended to liberate the human predictive process from preconceived lenses in data solicitation and/or interpretation. Efficacy, representativeness and generalizability are all heightened in this schema. Thus, the possible risks of biased big data arising from the inputs themselves must be acknowledged and addressed. Awareness of data deficiencies, structures for data inclusiveness, strategies for data sanitation, and mechanisms for data correction can help realize the potential of big data for a personalized medicine era. Applied deliberately, these considerations could help mitigate risks of perpetuation of health inequity amidst widespread adoption of novel applications of big data.},
	language = {en},
	number = {1},
	urldate = {2020-11-10},
	journal = {npj Digital Medicine},
	author = {Cahan, Eli M. and Hernandez-Boussard, Tina and Thadaney-Israni, Sonoo and Rubin, Daniel L.},
	month = aug,
	year = {2019},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1--6},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\J3BWWCNK\\Cahan et al. - 2019 - Putting the data before the algorithm in big data .pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\W6DJJZDZ\\s41746-019-0157-2.html:text/html}
}

@article{mosa_systematic_2012,
	title = {A {Systematic} {Review} of {Healthcare} {Applications} for {Smartphones}},
	volume = {12},
	issn = {1472-6947},
	url = {https://doi.org/10.1186/1472-6947-12-67},
	doi = {10.1186/1472-6947-12-67},
	abstract = {Advanced mobile communications and portable computation are now combined in handheld devices called “smartphones”, which are also capable of running third-party software. The number of smartphone users is growing rapidly, including among healthcare professionals. The purpose of this study was to classify smartphone-based healthcare technologies as discussed in academic literature according to their functionalities, and summarize articles in each category.},
	language = {en},
	number = {1},
	urldate = {2020-11-10},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Mosa, Abu Saleh Mohammad and Yoo, Illhoi and Sheets, Lincoln},
	month = jul,
	year = {2012},
	pages = {67},
	file = {Springer Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\G3RV66IK\\Mosa et al. - 2012 - A Systematic Review of Healthcare Applications for.pdf:application/pdf}
}

@article{ventola_mobile_2014,
	title = {Mobile {Devices} and {Apps} for {Health} {Care} {Professionals}: {Uses} and {Benefits}},
	volume = {39},
	issn = {1052-1372},
	shorttitle = {Mobile {Devices} and {Apps} for {Health} {Care} {Professionals}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4029126/},
	abstract = {Health care professionals’ use of mobile devices is transforming clinical practice. Numerous medical software applications can now help with tasks ranging from information and time management to clinical decision-making at the point of care.},
	number = {5},
	urldate = {2020-11-10},
	journal = {Pharmacy and Therapeutics},
	author = {Ventola, C. Lee},
	month = may,
	year = {2014},
	pmid = {24883008},
	pmcid = {PMC4029126},
	pages = {356--364},
	file = {PubMed Central Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\HHW3FJ3X\\Ventola - 2014 - Mobile Devices and Apps for Health Care Profession.pdf:application/pdf}
}

@article{boulos_how_2011,
	title = {How smartphones are changing the face of mobile and participatory healthcare: an overview, with example from {eCAALYX}},
	volume = {10},
	issn = {1475-925X},
	shorttitle = {How smartphones are changing the face of mobile and participatory healthcare},
	url = {https://doi.org/10.1186/1475-925X-10-24},
	doi = {10.1186/1475-925X-10-24},
	abstract = {The latest generation of smartphones are increasingly viewed as handheld computers rather than as phones, due to their powerful on-board computing capability, capacious memories, large screens and open operating systems that encourage application development. This paper provides a brief state-of-the-art overview of health and healthcare smartphone apps (applications) on the market today, including emerging trends and market uptake. Platforms available today include Android, Apple iOS, RIM BlackBerry, Symbian, and Windows (Windows Mobile 6.x and the emerging Windows Phone 7 platform). The paper covers apps targeting both laypersons/patients and healthcare professionals in various scenarios, e.g., health, fitness and lifestyle education and management apps; ambient assisted living apps; continuing professional education tools; and apps for public health surveillance. Among the surveyed apps are those assisting in chronic disease management, whether as standalone apps or part of a BAN (Body Area Network) and remote server configuration. We describe in detail the development of a smartphone app within eCAALYX (Enhanced Complete Ambient Assisted Living Experiment, 2009-2012), an EU-funded project for older people with multiple chronic conditions. The eCAALYX Android smartphone app receives input from a BAN (a patient-wearable smart garment with wireless health sensors) and the GPS (Global Positioning System) location sensor in the smartphone, and communicates over the Internet with a remote server accessible by healthcare professionals who are in charge of the remote monitoring and management of the older patient with multiple chronic conditions. Finally, we briefly discuss barriers to adoption of health and healthcare smartphone apps (e.g., cost, network bandwidth and battery power efficiency, usability, privacy issues, etc.), as well as some workarounds to mitigate those barriers.},
	number = {1},
	urldate = {2020-11-10},
	journal = {BioMedical Engineering OnLine},
	author = {Boulos, Maged N. Kamel and Wheeler, Steve and Tavares, Carlos and Jones, Ray},
	month = apr,
	year = {2011},
	pages = {24},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\XDUGZ5B9\\Boulos et al. - 2011 - How smartphones are changing the face of mobile an.pdf:application/pdf}
}

@article{nishiga_covid-19_2020,
	title = {{COVID}-19 and cardiovascular disease: from basic mechanisms to clinical perspectives},
	volume = {17},
	copyright = {2020 Springer Nature Limited},
	issn = {1759-5010},
	shorttitle = {{COVID}-19 and cardiovascular disease},
	url = {https://www.nature.com/articles/s41569-020-0413-9},
	doi = {10.1038/s41569-020-0413-9},
	abstract = {Coronavirus disease 2019 (COVID-19), caused by a strain of coronavirus known as severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), has become a global pandemic that has affected the lives of billions of individuals. Extensive studies have revealed that SARS-CoV-2 shares many biological features with SARS-CoV, the zoonotic virus that caused the 2002 outbreak of severe acute respiratory syndrome, including the system of cell entry, which is triggered by binding of the viral spike protein to angiotensin-converting enzyme 2. Clinical studies have also reported an association between COVID-19 and cardiovascular disease. Pre-existing cardiovascular disease seems to be linked with worse outcomes and increased risk of death in patients with COVID-19, whereas COVID-19 itself can also induce myocardial injury, arrhythmia, acute coronary syndrome and venous thromboembolism. Potential drug–disease interactions affecting patients with COVID-19 and comorbid cardiovascular diseases are also becoming a serious concern. In this Review, we summarize the current understanding of COVID-19 from basic mechanisms to clinical perspectives, focusing on the interaction between COVID-19 and the cardiovascular system. By combining our knowledge of the biological features of the virus with clinical findings, we can improve our understanding of the potential mechanisms underlying COVID-19, paving the way towards the development of preventative and therapeutic solutions.},
	language = {en},
	number = {9},
	urldate = {2020-11-10},
	journal = {Nature Reviews Cardiology},
	author = {Nishiga, Masataka and Wang, Dao Wen and Han, Yaling and Lewis, David B. and Wu, Joseph C.},
	month = sep,
	year = {2020},
	note = {Number: 9
Publisher: Nature Publishing Group},
	pages = {543--558},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\NFEW69GH\\Nishiga et al. - 2020 - COVID-19 and cardiovascular disease from basic me.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\92SSIVMX\\s41569-020-0413-9.html:text/html}
}

@article{dinh-le_wearable_2019,
	title = {Wearable {Health} {Technology} and {Electronic} {Health} {Record} {Integration}: {Scoping} {Review} and {Future} {Directions}},
	volume = {7},
	copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in JMIR mHealth and uHealth...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.},
	shorttitle = {Wearable {Health} {Technology} and {Electronic} {Health} {Record} {Integration}},
	url = {https://mhealth.jmir.org/2019/9/e12861},
	doi = {10.2196/12861},
	abstract = {Background:
Due to the adoption of electronic health records (EHRs) and legislation on meaningful use in recent decades, health systems are increasingly interdependent on EHR capabilities, offerings, and innovations to better capture patient data. A novel capability offered by health systems encompasses the integration between EHRs and wearable health technology. Although wearables have the potential to transform patient care, issues such as concerns with patient privacy, system interoperability, and patient data overload pose a challenge to the adoption of wearables by providers.
Methods:
We used a scoping process to survey existing efforts through Epic’s Web-based hub and discussion forum, UserWeb, and on the general Web, PubMed, and Google Scholar. We contacted Epic, because of their position as the largest commercial EHR system, for information on published client work in the integration of patient-collected data. Results from our searches had to meet criteria such as publication date and matching relevant search terms.
Results:
Numerous health institutions have started to integrate device data into patient portals. We identified the following 10 start-up organizations that have developed, or are in the process of developing, technology to enhance wearable health technology and enable EHR integration for health systems: Overlap, Royal Philips, Vivify Health, Validic, Doximity Dialer, Xealth, Redox, Conversa, Human API, and Glooko. We reported sample start-up partnerships with a total of 16 health systems in addressing challenges of the meaningful use of device data and streamlining provider workflows. We also found 4 insurance companies that encourage the growth and uptake of wearables through health tracking and incentive programs: Oscar Health, United Healthcare, Humana, and John Hancock.
Conclusions:
The future design and development of digital technology in this space will rely on continued analysis of best practices, pain points, and potential solutions to mitigate existing challenges. Although this study does not provide a full comprehensive catalog of all wearable health technology initiatives, it is representative of trends and implications for the integration of patient data into the EHR. Our work serves as an initial foundation to provide resources on implementation and workflows around wearable health technology for organizations across the health care industry.},
	language = {EN},
	number = {9},
	urldate = {2021-02-25},
	journal = {JMIR mHealth and uHealth},
	author = {Dinh-Le, Catherine and Chuang, Rachel and Chokshi, Sara and Mann, Devin},
	month = sep,
	year = {2019},
	note = {Company: JMIR mHealth and uHealth
Distributor: JMIR mHealth and uHealth
Institution: JMIR mHealth and uHealth
Label: JMIR mHealth and uHealth
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e12861},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\3HPWWHDQ\\e12861.html:text/html}
}

@misc{noauthor_atrium_nodate,
	title = {Atrium {Health} {Uses} {Telemedicine} to {Treat} {Eligible} {COVID}-19 {Patients} at {Home}},
	url = {https://atriumhealth.org/about-us/newsroom/news/2020/03/atrium-health-uses-telemedicine-to-treat-eligible-covid19-patients-at-home},
	abstract = {Atrium Health announced a new and innovate program to help appropriate patients who have been diagnosed with coronavirus disease 2019 (COVID-19) to receive safe and convenient treatment while they recover, in the comfort of their home. Atrium Health’s COVID-19 Virtual Hospital is designed to protect the patient’s health, the health of others and to prevent further spread of the infection.},
	language = {en},
	urldate = {2021-02-25},
	journal = {Atrium Health},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\NC2HK8RA\\atrium-health-uses-telemedicine-to-treat-eligible-covid19-patients-at-home.html:text/html}
}

@article{lukas_emerging_2020,
	title = {Emerging {Telemedicine} {Tools} for {Remote} {COVID}-19 {Diagnosis}, {Monitoring}, and {Management}},
	volume = {14},
	issn = {1936-0851},
	url = {https://doi.org/10.1021/acsnano.0c08494},
	doi = {10.1021/acsnano.0c08494},
	abstract = {The management of the COVID-19 pandemic has relied on cautious contact tracing, quarantine, and sterilization protocols while we await a vaccine to be made widely available. Telemedicine or mobile health (mHealth) is well-positioned during this time to reduce potential disease spread and prevent overloading of the healthcare system through at-home COVID-19 screening, diagnosis, and monitoring. With the rise of mass-fabricated electronics for wearable and portable sensors, emerging telemedicine tools have been developed to address shortcomings in COVID-19 diagnostics, monitoring, and management. In this Perspective, we summarize current implementations of mHealth sensors for COVID-19, highlight recent technological advances, and provide an overview on how these tools may be utilized to better control the COVID-19 pandemic.},
	number = {12},
	urldate = {2021-02-25},
	journal = {ACS Nano},
	author = {Lukas, Heather and Xu, Changhao and Yu, You and Gao, Wei},
	month = dec,
	year = {2020},
	note = {Publisher: American Chemical Society},
	pages = {16180--16193},
	file = {ACS Full Text Snapshot:C\:\\Users\\krish\\Zotero\\storage\\5DQTJSPQ\\acsnano.html:text/html;Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\KP82YS7L\\Lukas et al. - 2020 - Emerging Telemedicine Tools for Remote COVID-19 Di.pdf:application/pdf}
}

@article{steinhubl_emerging_2015,
	title = {The emerging field of mobile health},
	volume = {7},
	copyright = {Copyright © 2015, American Association for the Advancement of Science},
	issn = {1946-6234, 1946-6242},
	url = {https://stm.sciencemag.org/content/7/283/283rv3},
	doi = {10.1126/scitranslmed.aaa3487},
	abstract = {The surge in computing power and mobile connectivity have fashioned a foundation for mobile health (mHealth) technologies that can transform the mode and quality of clinical research and health care on a global scale. Unimpeded by geographical boundaries, smartphone-linked wearable sensors, point-of-need diagnostic devices, and medical-grade imaging, all built around real-time data streams and supported by automated clinical decision–support tools, will enable care and enhance our understanding of physiological variability. However, the path to mHealth incorporation into clinical care is fraught with challenges. We currently lack high-quality evidence that supports the adoption of many new technologies and have financial, regulatory, and security hurdles to overcome. Fortunately, sweeping efforts are under way to establish the true capabilities and value of the evolving mHealth field.
Mobile technologies can transform clinical research and health care worldwide—and save money.
Mobile technologies can transform clinical research and health care worldwide—and save money.},
	language = {en},
	number = {283},
	urldate = {2021-02-25},
	journal = {Science Translational Medicine},
	author = {Steinhubl, Steven R. and Muse, Evan D. and Topol, Eric J.},
	month = apr,
	year = {2015},
	pmid = {25877894},
	note = {Publisher: American Association for the Advancement of Science
Section: Review},
	pages = {283rv3--283rv3},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\UCSE7TFA\\Steinhubl et al. - 2015 - The emerging field of mobile health.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\5ELPWRRR\\283rv3.html:text/html}
}

@article{sawyer_wearable_2020,
	title = {Wearable {Internet} of {Medical} {Things} {Sensor} {Devices}, {Artificial} {Intelligence}-driven {Smart} {Healthcare} {Services}, and {Personalized} {Clinical} {Care} in {COVID}-19 {Telemedicine}},
	volume = {7},
	issn = {2334-4814, 2376-4481},
	url = {https://www.ceeol.com/search/article-detail?id=906655},
	language = {English},
	number = {2},
	urldate = {2021-02-25},
	journal = {American Journal of Medical Research},
	author = {Sawyer, Jennifer},
	year = {2020},
	note = {Publisher: Addleton Academic Publishers},
	pages = {71--77},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\T975U7MS\\article-detail.html:text/html}
}

@article{kumar_mobile_2013,
	title = {Mobile {Health}: {Revolutionizing} {Healthcare} {Through} {Transdisciplinary} {Research}},
	volume = {46},
	issn = {1558-0814},
	shorttitle = {Mobile {Health}},
	doi = {10.1109/MC.2012.392},
	abstract = {Mobile health (mHealth) seeks to improve individuals' health and well-being by continuously monitoring their status, rapidly diagnosing medical conditions, recognizing behaviors, and delivering just-in-time interventions, all in the user's natural mobile environment. The Web extra at http://youtu.be/o2mieSywutY is an audio interview in which Santosh Kumar, Wendy Nilsen, and Mani Srivastava discuss the path toward realizing mobile health systems.},
	number = {1},
	journal = {Computer},
	author = {Kumar, S. and Nilsen, W. and Pavel, M. and Srivastava, M.},
	month = jan,
	year = {2013},
	note = {Conference Name: Computer},
	keywords = {Biomedical monitoring, patient monitoring, healthcare, health care, Sensors, Biomedical imaging, computing in medicine, health monitoring, just-in-time intervention, m-health, medical computing, medical condition diagnosis, Medical services, mHealth, Mobile communication, mobile computing, Mobile handsets, mobile health system, patient diagnosis, regulation, sensor networks, transdisciplinary research, user natural mobile environment},
	pages = {28--35},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\ZM8SWZEB\\6357165.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\UIRSGXT3\\Kumar et al. - 2013 - Mobile Health Revolutionizing Healthcare Through .pdf:application/pdf}
}

@article{proesmans_mobile_2019,
	title = {Mobile {Phone}–{Based} {Use} of the {Photoplethysmography} {Technique} to {Detect} {Atrial} {Fibrillation} in {Primary} {Care}: {Diagnostic} {Accuracy} {Study} of the {FibriCheck} {App}},
	volume = {7},
	copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in JMIR mHealth and uHealth...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.},
	shorttitle = {Mobile {Phone}–{Based} {Use} of the {Photoplethysmography} {Technique} to {Detect} {Atrial} {Fibrillation} in {Primary} {Care}},
	url = {https://mhealth.jmir.org/2019/3/e12284},
	doi = {10.2196/12284},
	abstract = {Background: Mobile phone apps using photoplethysmography (PPG) technology through their built-in camera are becoming an attractive alternative for atrial fibrillation (AF) screening because of their low cost, convenience, and broad accessibility. However, some important questions concerning their diagnostic accuracy remain to be answered. Objective: This study tested the diagnostic accuracy of the FibriCheck AF algorithm for the detection of AF on the basis of mobile phone PPG and single-lead electrocardiography (ECG) signals. Methods: A convenience sample of patients aged 65 years and above, with or without a known history of AF, was recruited from 17 primary care facilities. Patients with an active pacemaker rhythm were excluded. A PPG signal was obtained with the rear camera of an iPhone 5S. Simultaneously, a single‑lead ECG was registered using a dermal patch with a wireless connection to the same mobile phone. PPG and single-lead ECG signals were analyzed using the FibriCheck AF algorithm. At the same time, a 12‑lead ECG was obtained and interpreted offline by independent cardiologists to determine the presence of AF. Results: A total of 45.7\% (102/223) subjects were having AF. PPG signal quality was sufficient for analysis in 93\% and single‑lead ECG quality was sufficient in 94\% of the participants. After removing insufficient quality measurements, the sensitivity and specificity were 96\% (95\% CI 89\%-99\%) and 97\% (95\% CI 91\%-99\%) for the PPG signal versus 95\% (95\% CI 88\%-98\%) and 97\% (95\% CI 91\%-99\%) for the single‑lead ECG, respectively. False-positive results were mainly because of premature ectopic beats. PPG and single‑lead ECG techniques yielded adequate signal quality in 196 subjects and a similar diagnosis in 98.0\% (192/196) subjects. Conclusions: The FibriCheck AF algorithm can accurately detect AF on the basis of mobile phone PPG and single-lead ECG signals in a primary care convenience sample.},
	language = {EN},
	number = {3},
	urldate = {2021-02-25},
	journal = {JMIR mHealth and uHealth},
	author = {Proesmans, Tine and Mortelmans, Christophe and Haelst, Ruth Van and Verbrugge, Frederik and Vandervoort, Pieter and Vaes, Bert},
	month = mar,
	year = {2019},
	note = {Company: JMIR mHealth and uHealth
Distributor: JMIR mHealth and uHealth
Institution: JMIR mHealth and uHealth
Label: JMIR mHealth and uHealth
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e12284},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\JFQ49GZ8\\Proesmans et al. - 2019 - Mobile Phone–Based Use of the Photoplethysmography.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\PWHHSN9G\\e12284.html:text/html}
}

@article{li_current_2019,
	title = {The {Current} {State} of {Mobile} {Phone} {Apps} for {Monitoring} {Heart} {Rate}, {Heart} {Rate} {Variability}, and {Atrial} {Fibrillation}: {Narrative} {Review}},
	volume = {7},
	copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in JMIR mHealth and uHealth...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.},
	shorttitle = {The {Current} {State} of {Mobile} {Phone} {Apps} for {Monitoring} {Heart} {Rate}, {Heart} {Rate} {Variability}, and {Atrial} {Fibrillation}},
	url = {https://mhealth.jmir.org/2019/2/e11606},
	doi = {10.2196/11606},
	abstract = {Background: Mobile phone apps capable of monitoring arrhythmias and heart rate (HR) are increasingly used for screening, diagnosis, and monitoring of HR and rhythm disorders such as atrial fibrillation (AF). These apps involve either the use of (1) photoplethysmographic recording or (2) a handheld external electrocardiographic recording device attached to the mobile phone or wristband. Objective: This review seeks to explore the current state of mobile phone apps in cardiac rhythmology while highlighting shortcomings for further research. Methods: We conducted a narrative review of the use of mobile phone devices by searching PubMed and EMBASE from their inception to October 2018. Potentially relevant papers were then compared against a checklist for relevance and reviewed independently for inclusion, with focus on 4 allocated topics of (1) mobile phone monitoring, (2) AF, (3) HR, and (4) HR variability (HRV). Results: The findings of this narrative review suggest that there is a role for mobile phone apps in the diagnosis, monitoring, and screening for arrhythmias and HR. Photoplethysmography and handheld electrocardiograph recorders are the 2 main techniques adopted in monitoring HR, HRV, and AF. Conclusions: A number of studies have demonstrated high accuracy of a number of different mobile devices for the detection of AF. However, further studies are warranted to validate their use for large scale AF screening.},
	language = {EN},
	number = {2},
	urldate = {2021-02-25},
	journal = {JMIR mHealth and uHealth},
	author = {Li, Ka Hou Christien and White, Francesca Anne and Tipoe, Timothy and Liu, Tong and Wong, Martin CS and Jesuthasan, Aaron and Baranchuk, Adrian and Tse, Gary and Yan, Bryan P.},
	month = feb,
	year = {2019},
	note = {Company: JMIR mHealth and uHealth
Distributor: JMIR mHealth and uHealth
Institution: JMIR mHealth and uHealth
Label: JMIR mHealth and uHealth
Publisher: JMIR Publications Inc., Toronto, Canada},
	pages = {e11606},
	file = {Full Text:C\:\\Users\\krish\\Zotero\\storage\\X39E2IXS\\Li et al. - 2019 - The Current State of Mobile Phone Apps for Monitor.pdf:application/pdf;Snapshot:C\:\\Users\\krish\\Zotero\\storage\\BLTPZRZB\\e11606.html:text/html}
}

@article{nowara_near-infrared_2020,
	title = {Near-{Infrared} {Imaging} {Photoplethysmography} {During} {Driving}},
	issn = {1558-0016},
	doi = {10.1109/TITS.2020.3038317},
	abstract = {Imaging photoplethysmography (iPPG) could greatly improve driver safety systems by enabling capabilities ranging from identifying driver fatigue to unobtrusive early heart failure detection. Unfortunately, the driving context poses unique challenges to iPPG, including illumination and motion. First, drastic illumination variations present during driving can overwhelm the small intensity-based iPPG signals. Second, significant driver head motion during driving, as well as camera motion (e.g., vibration) make it challenging to recover iPPG signals. To address these two challenges, we present two innovations. First, we demonstrate that we can reduce most outside light variations using narrow-band near-infrared (NIR) video recordings and obtain reliable heart rate estimates. Second, we present a novel optimization algorithm, which we call AutoSparsePPG, that leverages the quasi-periodicity of iPPG signals and achieves better performance than the state-of-the-art methods. In addition, we release the first publicly available driving dataset that contains both NIR and RGB video recordings of a passenger's face with simultaneous ground truth pulse oximeter recordings.},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Nowara, E. M. and Marks, T. K. and Mansour, H. and Veeraraghavan, A.},
	year = {2020},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Cameras, Remote photoplethysmography, Heart rate, Robustness, Lighting, heart rate, imaging photoplethysmography, Automobiles, driver monitoring., Faces, near-infrared, Vehicles},
	pages = {1--12},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\krish\\Zotero\\storage\\WQ5JLNAP\\9275394.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\7U5C68XD\\Nowara et al. - 2020 - Near-Infrared Imaging Photoplethysmography During .pdf:application/pdf}
}

@misc{noauthor_osa_nodate,
	title = {{OSA} {\textbar} {Systematic} analysis of video-based pulse measurement from compressed videos},
	url = {https://www.osapublishing.org/boe/fulltext.cfm?uri=boe-12-1-494&id=444959},
	urldate = {2021-02-25},
	file = {OSA | Systematic analysis of video-based pulse measurement from compressed videos:C\:\\Users\\krish\\Zotero\\storage\\W59ZF8Q9\\fulltext.html:text/html}
}

@article{nowara_systematic_2021,
	title = {Systematic analysis of video-based pulse measurement from compressed videos},
	volume = {12},
	copyright = {\&\#169; 2020 Optical Society of America},
	issn = {2156-7085},
	url = {https://www.osapublishing.org/boe/abstract.cfm?uri=boe-12-1-494},
	doi = {10.1364/BOE.408471},
	abstract = {Camera-based physiological measurement enables vital signs to be captured unobtrusively without contact with the body. Remote, or imaging, photoplethysmography involves recovering peripheral blood flow from subtle variations in video pixel intensities. While the pulse signal might be easy to obtain from high quality uncompressed videos, the signal-to-noise ratio drops dramatically with video bitrate. Uncompressed videos incur large file storage and data transfer costs, making analysis, manipulation and sharing challenging. To help address these challenges, we use compression specific supervised models to mitigate the effect of temporal video compression on heart rate estimates. We perform a systematic evaluation of the performance of state-of-the-art algorithms across different levels, and formats, of compression. We demonstrate that networks trained on compressed videos consistently outperform other benchmark methods, both on stationary videos and videos with significant rigid head motions. By training on videos with the same, or higher compression factor than test videos, we achieve improvements in signal-to-noise ratio (SNR) of up to 3 dB and mean absolute error (MAE) of up to 6 beats per minute (BPM).},
	language = {EN},
	number = {1},
	urldate = {2021-02-25},
	journal = {Biomedical Optics Express},
	author = {Nowara, Ewa M. and McDuff, Daniel and Veeraraghavan, Ashok},
	month = jan,
	year = {2021},
	note = {Publisher: Optical Society of America},
	pages = {494--508},
	file = {Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\RP8P8MLB\\Nowara et al. - 2021 - Systematic analysis of video-based pulse measureme.pdf:application/pdf}
}

@article{mensah_cardiovascular_2018,
	series = {African {Americans} and {Kidney} {Disease} in the 21st {Century}},
	title = {Cardiovascular {Diseases} in {African} {Americans}: {Fostering} {Community} {Partnerships} to {Stem} the {Tide}},
	volume = {72},
	issn = {0272-6386},
	shorttitle = {Cardiovascular {Diseases} in {African} {Americans}},
	url = {https://www.sciencedirect.com/science/article/pii/S0272638618308321},
	doi = {10.1053/j.ajkd.2018.06.026},
	abstract = {In 2002, the Institute of Medicine highlighted community partnerships as important in strategies for ensuring the public’s health in the 21st century. Whether defined narrowly as the neighborhood or more broadly as the entire nation, communities represent settings in which health is supported and protected by healthy social connections and environments or risked and damaged by detrimental social, environmental, and policy determinants, as well as adverse behavioral and lifestyle choices. In this article, cardiovascular disease in African Americans is used as an example to highlight the successes achieved during the last half-century in reducing mortality rates, the persisting challenge of suboptimal adoption of evidence-based practices to promote community health and prevent disease, and the still widespread and pervasive health disparities. The article concludes with a call for the scientific community to embrace implementation research in strategic partnership with community stakeholders to stem the tide of cardiovascular disease and reduce related cardiovascular health disparities.},
	language = {en},
	number = {5, Supplement 1},
	urldate = {2021-02-25},
	journal = {American Journal of Kidney Diseases},
	author = {Mensah, George A.},
	month = nov,
	year = {2018},
	keywords = {environment, African Americans, Cardiovascular disease, community, disparities, health disparities, heart disease, implementation research, lifestyle, partnerships, public health, residence characteristics, review, risk, stroke},
	pages = {S37--S42},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\krish\\Zotero\\storage\\J7QG9MIN\\Mensah - 2018 - Cardiovascular Diseases in African Americans Fost.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\krish\\Zotero\\storage\\JMIHPEES\\S0272638618308321.html:text/html}
}

@techreport{polaris_us_2020,
	address = {New York},
	title = {U.{S}. {Telemedicine} {Market} {Share}, {Size}, {Trends}, {Industry} {Analysis} {Report} {By} {Component} ({Hardware}, {Software} \& {Services}); {By} {Application} ({Teleradiology}, {Telepsychiatry}, {Telestroke}, {Tele}-{ICU}, {Teledermatology}, {Teleconsultation}); {Mode} of {Delivery} ({Mobile} {Health} {Apps}, {Virtual}, {Telehealth} {Portals} \& {Kiosks}), {By} {End} {User} ({Providers}, {Payers}, {Patients}); {Segment} {Forecast}, 2020 - 2027},
	url = {https://www.polarismarketresearch.com/industry-analysis/us-telemedicine-market},
	language = {en-US},
	number = {PM1672},
	urldate = {2021-03-01},
	institution = {Polaris Market Research},
	month = aug,
	year = {2020},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\BHBT4RU6\\us-telemedicine-market.html:text/html}
}

@article{kats_us_2020,
	title = {{US} telemedicine users will surpass 40 million this year},
	url = {https://www.emarketer.com/content/us-telemedicine-users-will-surpass-40-million-this-year},
	abstract = {Telemedicine users in the US will reach 41.67 million in 2020, representing a growth of 98.8\% from a year prior, according to our latest estimates.},
	day = {30}, 
	month = nov, 
	year = {2020},
	urldate = {2021-05-02},
	journal = {eMarketer},
	author = {Kats, Rimma},
	file = {Snapshot:C\:\\Users\\krish\\Zotero\\storage\\FQQZ7APY\\us-telemedicine-users-will-surpass-40-million-this-year.html:text/html}
}

@misc{cps_us_2020, 
    title={Current Population Survey ({CPS})},
    url={https://www.census.gov/programs-surveys/cps.html},
    howpublished={{The United States Census Bureau}},
    publisher={US Census Bureau},
    year={2020},
    month={Nov}
}

@article {kadambi_achieving_2021,
	author = {Kadambi, Achuta},
	title = {Achieving fairness in medical devices},
	volume = {372},
	number = {6537},
	pages = {30--31},
	year = {2021},
	doi = {10.1126/science.abe9195},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/372/6537/30},
	eprint = {https://science.sciencemag.org/content/372/6537/30.full.pdf},
	journal = {Science}
}

@inproceedings{mironenko_remote_2020,
  title={Remote Photoplethysmography: Rarely Considered Factors},
  author={Mironenko, Yuriy and Kalinin, Konstantin and Kopeliovich, Mikhail and Petrushan, Mikhail},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={296--297},
  year={2020}
}
@inproceedings{tang_noncontact_2018,
  title={Non-contact heart rate monitoring by combining convolutional neural network skin detection and remote photoplethysmography via a low-cost camera},
  author={Tang, Chuanxiang and Lu, Jiwu and Liu, Jie},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={1309--1315},
  year={2018}
}

@article{mocco_motion_2016,
  title={Motion robust PPG-imaging through color channel mapping},
  author={Mo{\c{c}}o, Andreia V and Stuijk, Sander and de Haan, Gerard},
  journal={Biomedical Optics Express},
  volume={7},
  number={5},
  pages={1737--1754},
  year={2016},
  publisher={Optical Society of America}
}

@article{krishnaswamy_biophysically_2004,
author = {Krishnaswamy, Aravind and Baranoski, Gladimir V.G.},
title = {A Biophysically-Based Spectral Model of Light Interaction with Human Skin},
journal = {Computer Graphics Forum},
volume = {23},
number = {3},
pages = {331-340},
doi = {https://doi.org/10.1111/j.1467-8659.2004.00764.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2004.00764.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2004.00764.x},
abstract = {Abstract Despite the notable progress in physically-based rendering, there is still a long way to go before we can automatically generate predictable images of biological materials. In this paper, we address an open problem in this area, namely the spectral simulation of light interaction with human skin. We propose a novel biophysically based model that accounts for all components of light propagation in skin tissues, namely surface reflectance, subsurface reflectance and transmittance, and the biological mechanisms of light absorption by pigments in these tissues. The model is controlled by biologically meaningful parameters, and its formulation, based on standard Monte Carlo techniques, enables its straightforward incorporation into realistic image synthesis frameworks. Besides its biophysically-based nature, the key difference between the proposed model and the existing skin models is its comprehensiveness, i.e., it computes both spectral (reflectance and transmittance) and scattering (bidirectional surface-scattering distribution function) quantities for skin specimens. In order to assess the predictability of our simulations, we evaluate their accuracy by comparing results from the model with actual skin measured data. We also present computer generated images to illustrate the flexibility of the proposed model with respect to variations in the biological input data, and its applicability not only in the predictive image synthesis of different skin tones, but also in the spectral simulation of medical conditions. Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism},
year = {2004}
}

@inproceedings{nowara_combating_2019,
  title={Combating the impact of video compression on non-contact vital sign measurement using supervised learning},
  author={Nowara, Ewa and McDuff, Daniel},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={1706–1712},
  year={2019}
}

@article{brandao_age_2019,
  title={Age and gender bias in pedestrian detection algorithms},
  author={Brandao, Martim},
  journal={arXiv preprint arXiv:1906.10490},
  year={2019}
}

@inproceedings{buolamwini_gender_2018,
  title={Gender shades: Intersectional accuracy disparities in commercial gender classification},
  author={Buolamwini, Joy and Gebru, Timnit},
  booktitle={Conference on fairness, accountability and transparency},
  pages={77--91},
  year={2018},
  organization={PMLR}
}

@article{klare_face_2012,
  title={Face recognition performance: Role of demographic information},
  author={Klare, Brendan F and Burge, Mark J and Klontz, Joshua C and Bruegge, Richard W Vorder and Jain, Anil K},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={7},
  number={6},
  pages={1789--1801},
  year={2012},
  publisher={IEEE}
}

@inproceedings{vangara_characterizing_2019,
  title={Characterizing the variability in face recognition accuracy relative to race},
  author={Vangara, Kushal and King, Michael C and Albiero, Vitor and Bowyer, Kevin and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--0},
  year={2019}
}

@article{rouast_remote_2018,
  title={Remote heart rate measurement using low-cost RGB face video: a technical literature review},
  author={Rouast, Philipp V and Adam, Marc TP and Chiong, Raymond and Cornforth, David and Lux, Ewa},
  journal={Frontiers of Computer Science},
  volume={12},
  number={5},
  pages={858--872},
  year={2018},
  publisher={Springer}
}

@misc{pew_demographics_2019, 
    title={{Demographics of Mobile Device Ownership and Adoption in the United States}},
    url={https://www.pewresearch.org/internet/fact-sheet/mobile/},
    publisher={Pew Research Center},
    howpublished={{Pew Research Center}},
    year={2019},
    month={June}
}

@book{igarashi_appearance_2007,
  title={The appearance of human skin: A survey},
  author={Igarashi, Takanori and Nishino, Ko and Nayar, Shree K},
  year={2007},
  publisher={Now Publishers Inc}
}

@article{anderson_optics_1981,
title = {The Optics of Human Skin},
journal = {Journal of Investigative Dermatology},
volume = {77},
number = {1},
pages = {13-19},
year = {1981},
issn = {0022-202X},
doi = {https://doi.org/10.1111/1523-1747.ep12479191},
url = {https://www.sciencedirect.com/science/article/pii/S0022202X15461251},
author = {R. Rox Anderson and John A. Parrish},
abstract = {An integrated review of the transfer of optical radiation into human skin is presented, aimed at developing useful models for photomedicine. The component chromophores of epidermis and stratum corneum in general determine the attenuation of radiation in these layers, moreso than does optical scattering. Epidermal thickness and melanization are important factors for UV wavelengths less than 300nm, whereas the attenuation of UVA (320–400nm) and visible radiation is primarily via melanin. The selective penetration of all optical wavelengths into psoriatic skin can be maximized by application of clear lipophilic liquids, which decrease regular reflectance by a refractive-index matching mechanism. Sensitivity to wavelengths less than 320nm can be enhanced by prolonged aqueous bathing, which extracts urocanic acid and other diffusible epidermal chromophores. Optical properties of the dermis are modelled using the Kubelka-Munk approach, and calculations of scattering and absorption coefficients are presented. This simple approach allows estimates of the penetration of radiation in vivo using noninvasive measurements of cutaneous spectral remittance (diffuse reflectance). Although the blood chromophores Hb, HbO2, and bilirubin determine dermal absorption of wavelengths longer than 320nm, scattering by collagen fibers largely determines the depths to which these wavelengths penetrate the dermis, and profoundly modifies skin colors. An optical “window” exists between 600 and 1300nm, which offers the possibility of treating large tissue volumes with certain long-wavelength photosensitizers. Moreover, whenever photosensitized action spectra extend across the near UV and/or visible spectrum, judicious choice of wavelength allows some selection of the tissue layers directly affected.}
}

@article{jablonski_evolution_2000,
title = {The evolution of human skin coloration},
journal = {Journal of Human Evolution},
volume = {39},
number = {1},
pages = {57-106},
year = {2000},
issn = {0047-2484},
doi = {https://doi.org/10.1006/jhev.2000.0403},
url = {https://www.sciencedirect.com/science/article/pii/S0047248400904032},
author = {Nina G. Jablonski and George Chaplin},
keywords = {ultraviolet radiation, UVB, melanin, integument, folate, photoprotection, neural tube defects, vitamin D, depigmentation, thermoregulation, race concepts},
abstract = {Skin color is one of the most conspicuous ways in which humans vary and has been widely used to define human races. Here we present new evidence indicating that variations in skin color are adaptive, and are related to the regulation of ultraviolet (UV) radiation penetration in the integument and its direct and indirect effects on fitness. Using remotely sensed data on UV radiation levels, hypotheses concerning the distribution of the skin colors of indigenous peoples relative to UV levels were tested quantitatively in this study for the first time. The major results of this study are: (1) skin reflectance is strongly correlated with absolute latitude and UV radiation levels. The highest correlation between skin reflectance and UV levels was observed at 545nm, near the absorption maximum for oxyhemoglobin, suggesting that the main role of melanin pigmentation in humans is regulation of the effects of UV radiation on the contents of cutaneous blood vessels located in the dermis. (2) Predicted skin reflectances deviated little from observed values. (3) In all populations for which skin reflectance data were available for males and females, females were found to be lighter skinned than males. (4) The clinal gradation of skin coloration observed among indigenous peoples is correlated with UV radiation levels and represents a compromise solution to the conflicting physiological requirements of photoprotection and vitamin D synthesis. The earliest members of the hominid lineage probably had a mostly unpigmented or lightly pigmented integument covered with dark black hair, similar to that of the modern chimpanzee. The evolution of a naked, darkly pigmented integument occurred early in the evolution of the genus Homo. A dark epidermis protected sweat glands from UV-induced injury, thus insuring the integrity of somatic thermoregulation. Of greater significance to individual reproductive success was that highly melanized skin protected against UV-induced photolysis of folate (Branda & Eaton, 1978, Science201, 625–626; Jablonski, 1992, Proc. Australas. Soc. Hum. Biol.5, 455–462, 1999, Med. Hypotheses52, 581–582), a metabolite essential for normal development of the embryonic neural tube (Bower & Stanley, 1989, The Medical Journal of Australia150, 613–619; Medical Research Council Vitamin Research Group, 1991, The Lancet338, 31–37) and spermatogenesis (Cosentino et al., 1990, Proc. Natn. Acad. Sci. U.S.A.87, 1431–1435; Mathur et al., 1977, Fertility Sterility28, 1356–1360). As hominids migrated outside of the tropics, varying degrees of depigmentation evolved in order to permit UVB-induced synthesis of previtamin D3. The lighter color of female skin may be required to permit synthesis of the relatively higher amounts of vitamin D3necessary during pregnancy and lactation. Skin coloration in humans is adaptive and labile. Skin pigmentation levels have changed more than once in human evolution. Because of this, skin coloration is of no value in determining phylogenetic relationships among modern human groups.}
}

@article{nitzan_pulse_2014,
  title={Pulse oximetry: fundamentals and technology update},
  author={Nitzan, Meir and Romem, Ayal and Koppel, Robert},
  journal={Medical Devices (Auckland, NZ)},
  volume={7},
  pages={231},
  year={2014},
  publisher={Dove Press}
}

@article{sjoding_racial_2020,
    author = {Sjoding, Michael W. and Dickson, Robert P. and Iwashyna, Theodore J. and Gay, Steven E. and Valley, Thomas S.},
    title = {Racial Bias in Pulse Oximetry Measurement},
    journal = {New England Journal of Medicine},
    volume = {383},
    number = {25},
    pages = {2477-2478},
    year = {2020},
    doi = {10.1056/NEJMc2029240},
    note ={PMID: 33326721},
    URL = {https://doi.org/10.1056/NEJMc2029240},
    eprint = {https://doi.org/10.1056/NEJMc2029240}
}