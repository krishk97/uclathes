%
% conclusions.tex
% Copyright (C) 2021 by Krish Kabra, <krish@kabra.com>.
%

\chapter{Conclusions} \label{chap:conclusion}

In this thesis, we propose a novel R-PPG algorithm to estimate subject HR in a contactless manner using only a smartphone camera. Several R-PPG algorithms have been proposed to extract the BVP signal from videos; however, these algorithms exhibit a performance gap, and therefore a bias, for certain types of skin tones \cite{nowara_meta-analysis_2020}, subject motions (e.g. speaking) \cite{mocco_motion_2016,de_haan_improved_2014,wang_exploiting_2015}, and illumination conditions \cite{li_remote_2014}. Addressing these biases is essential for successful deployment of R-PPG technology in telemedicine applications, yet it remains a challenge. For example, we mathemetically show that dark skin, which contains higher amounts of melanin, fundamentally reduces the SNR of  R-PPG. Nowara et al. \cite{nowara_meta-analysis_2020} highlights this reduction, thereby conclusively determining that current R-PPG algorithms have markedly worse performance on darker skin tones. The work also highlights the issue of biased skin tone and gender representation in computer vision datasets, which is especially true for the comparatively small datasets used in R-PPG analyses. This dataset bias further prevents underlying light-transport biases, such as skin tone bias, from being addressed. Should contactless HR sensing using video be implemented in a clinical setting, the development of R-PPG computer vision algorithms and datasets that improve the accuracy and reduce the bias of HR measurements for patients of all skin tones (especially the darker skin tones) is critically necessary for high-quality telemedicine care.

A key contribution of this work is the creation of the VITAL dataset, which is a first effort towards collecting a demographically diverse video vital sign database for telemedicine applications. While societal demographics are skewed largely towards light skin tone persons, it is essential to have diversely represented computer vision healthcare datasets to understand performance limitations that may otherwise be masked within biased data \cite{cahan_putting_2019}. Although the VITAL dataset is not entirely unbiased itself, it achieves a much higher degree of skin tone diversity as compared to existing datasets. Moreover, the VITAL dataset records facial videos using smartphone cameras, which introduces significant video compression and imaging noise artifacts. Typically, R-PPG methods are developed and tested using uncompressed videos. However, deployment of R-PPG technology for telemedicine will ultimately require a robustness to video compression noise artifacts. Therefore, the VITAL dataset enables a more realistic evaluation of remote video-based vital sign monitoring methods for telemedicine translation, which contrasts from previous works. Finally, the VITAL dataset captures four ground truth vital signs: HR, respiratory rate, oxygen saturation, and non-invasive continuous blood pressure, of which three waveforms are collected: ECG, PPG and respiration. Although this work only utilizes the HR obtained from the PPG waveform for testing, we anticipate future work capturing all four vital signs simultaneously from the facial videos. Overall, we envision the VITAL dataset to be an essential resource for upcoming related research and, in addition, to set the tone for future data collection endeavors for similar interdisciplinary clinical cum technological applications.

With respect to algorithmic development, this work addresses the aforementioned biases in skin-tone, illumination conditions, and subject motions using physics-rooted knowledge and camera noise analysis. From our theory, we derive 2 key conclusions: (i) imaging noise creates skin tone bias (and lighting bias), and (ii) imaging noise and specular reflections degrade the R-PPG signal. Therefore, we primarily focus our attention to signal processing strategies as opposed to signal extraction modifications. The first attempted work to reduce R-PPG skin tone bias was done by Kumar et al. (DistancePPG) \cite{kumar_distanceppg_2015}, in which a weighted average of BVP signals from various facial ROIs. However, to the best of the authors’ knowledge, no work yet has continued development of R-PPG algorithms that tackle the important issue of performance bias on darker skin tones. The proposed R-PPG algorithm draws from existing R-PPG denoising methods that use a similar weighted ROI philosophy as in DistancePPG (c.f. \cite{po_block-based_2018,li_model-based_2020,bobbia_unsupervised_2019}). Specifically, it modifies the signal combination step by combining signal information from various facial ROIs in the frequency-domain rather than the time-domain. Moreover, it introduces a skin diffuse component weighting when averaging the signal information. This enables the proposed algorithm to drastically mitigate performance losses for subjects with darker skin tones, subjects in varying illumination conditions, and subjects who may be moving their face such as when they are talking. 

The proposed method achieves the best overall average MAE performance across the VITAL dataset of 7.62 bpm, as opposed to 10.04 bpm by the facial aggregation method \cite{poh_noncontact_2010,haan_robust_2013,wang_novel_2016,wang_algorithmic_2017,lewandowska_measuring_2011,de_haan_improved_2014} and 10.48 bpm for the SNR weighting method \cite{po_block-based_2018,li_model-based_2020,kumar_distanceppg_2015,bobbia_unsupervised_2019}. This achievement can be attributed to the performance gains seen across all skin tones in comparison to the facial aggregation method. The SNR weighting method shows performance gain only for the light skin tone subjects (+0.39 bpm) and a performance drop for the medium and dark skin tones (-1.22 and -0.24 bpm respectively), thereby actually increasing the skin tone performance bias. Consequently, the method’s overall performance suffers on a more diversely represented dataset such as VITAL. This illustrates the importance for the need of a truly diverse dataset when developing R-PPG technology.

Nevertheless, as with previous methods, the performance of the proposed method still exhibits a skin-tone bias. However, we highlight that the proposed method achieves the largest MAE improvements over the facial aggregation method of 28.5\% (+4.11 bpm) for the traditionally worse performing dark skin tone in comparison with the light (20.2\%, +1.71 bpm) and medium (23.7\%, +2.22 bpm) skin tones. This outcome attests to the fairness of the method. The proposed method is the only method able to perform with an overall MAE less than 8 bpm across all skin tones. These inferences are further enforced by the significant decrease in the SDE and overall improvement in the correlation coefficient, as opposed to the SNR weighting method which sees performance reduction for medium and dark skin tones. Hence, in addition to the overall improvement in performance across all skin tones, the proposed method successfully steps towards reducing the performance bias that exists between skin tones. If the VITAL dataset were to have even more equal representation in terms of skin tone, the overall average performance measures are further expected to improve. 

Large improvements in performance of the proposed method are also observed for the talking activity over the facial aggregation benchmark, as compared to the SNR weighting method which shows an overall performance drop. This technology may one day allow for real-time continuous contact-less HR monitoring during a telemedicine visit, which would provide greater information to outpatient clinicians. This advance may also be relevant for in-hospital continuous contactless monitoring in ICU settings or hospital floor care.
Improvements in performance are also observed across camera viewpoints. The proposed method shows considerable improvements for the front and bottom angles. A typical telemedicine visit, through a cell phone platform, may involve the patient holding the camera at varying angles with respect to the face. The shown robustness and performance improvement of the proposed method therefore makes it increasingly amenable to such tasks. Interestingly, for all methods tested (existing and novel), the bottom angle shows improved performance as compared to the front angle. This could be because interfering factors such as hair, spectacles and so on occupy a smaller portion of the usable frame in the bottom angle, as well as differing face scales in the two angles.

In relation to the clinical significance of this work, remote vital sign monitoring has risen in prominence over recent years, with an acceleration in clinical development due to the COVID-19 pandemic. In response to the pandemic, health systems across the country implemented a large-scale restriction of non-urgent in-person appointments \cite{jm_virtual_2020}, transitioned many outpatient services to telemedicine visits \cite{connolly_rapid_2020}, and developed remote monitoring care pathways \cite{annis_rapid_2020} in order to facilitate social distancing yet maintain continuity of care. To remotely monitor COVID-19 patients, many health systems shipped home vital sign equipment to patients in order to obtain quantitative physiological data that could facilitate high quality remote management via telemedicine. At a population level, however, supplying and shipping vital sign monitoring devices to patients is expensive and not scalable, making such a solution nonviable. For the scales at which telemedicine is projected to grow, the projected cost of deploying finger pulse oximeters for telemedicine application, the most viable and inexpensive existing solution to assess patient HR and oxygen saturation, would involve a deployment cost in excess of \$700 million in the US alone (see Appendix~\ref{chap:telemedicine_cost_projections} for calculation details) \cite{polaris_us_2020}. Given the high penetration of mobile phone technology globally \cite{pew_demographics_2019}, there is great interest in transforming smartphones into low-cost portable HR, respiratory rate, and pulse oximeter monitors, thereby increasing accessibility to vital monitoring equipment and alleviating healthcare inequity. Using in-built camera modules and computer vision algorithms to obtain quantitative vital sign data remotely offers a purely algorithmic solution with potentially zero marginal cost. 

Outside of a pandemic situation, knowledge of vital signs is also important information for clinicians who are managing medical conditions that require such data for health management, and remotely obtaining vital signs may allow care teams to perform remote surveillance and home monitoring of patients with greater confidence. Notably, several minority and lower socioeconomic status patient populations may benefit from more remote care, especially as it has been established that the COVID-19 pandemic has disproportionately affected such communities, both nationally and in states the most affected by the pandemic \cite{abedi_racial_2020,azar_disparities_2020}. In New York City and Michigan, African American and Latino residents have the highest age-adjusted rates of hospitalized and non-hospitalized COVID-19, and age-adjusted death rates for African Americans are more than twice those for white and Asian residents \cite{holtgrave_assessing_2020,gu_characteristics_2020}. African American communities have also been found to have higher prevalence of cardiovascular and related complications, when compared with traditionally light skin toned people \cite{mensah_cardiovascular_2018}. These patient populations may therefore stand to benefit the most from skin tone robust contactless vital sign (specifically heart rate) sensing technologies that facilitate high-quality remote care pathways. Finally, we believe contactless vital sign sensing technology would be useful at the start of in-person clinic or hospital encounters or for continuous patient monitoring in a hospital floor or ICU setting. Cameras, as opposed to hospital staff, may one day obtain key vital signs without contact, thereby reducing exposure of patients to staff, enabling improved infection control, and freeing up hospital staff to attend to other important patient care needs.  

With regards to limitations and future work, while our method has been tested on an adult population, additional work is needed to enable clinical adoption.  Further research investigating HR estimation using our proposed method is still needed in pediatric and geriatric populations and patient populations with known cardiopulmonary disease. Future work must also focus on improving computer vision methods to detect extremes of HR and discern heart arrhythmias. Additionally, the proposed method does not obviate skin tone bias but rather is the first work that can be demonstrated to mitigate skin tone bias in the VITAL dataset. Therefore, research must be undertaken to further reduce bias and assure fairness by building upon our work, as well as to continue improving overall performance on subjects and videos in real life scenarios. 
 
From an algorithmic perspective, we believe that one of the most important factors towards large scale deployment of such methods for clinical use is the inherent fairness of the algorithm. As healthcare increasingly accelerates towards a digitally connected and virtual future, early consideration must be given to developing equitable health technology that does not exacerbate healthcare disparities or create new disparities. Ultimately, we hope this work motivates the community towards exciting and essential research avenues looking into inherent system biases associated with R-PPG. By reducing biases, we move a step closer towards deploying high-quality, medically inclusive non-contact vital sensing techniques that can aid clinicians in delivering remote patient care, during times of peace and pandemic alike.



