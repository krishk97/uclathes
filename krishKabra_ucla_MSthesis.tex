
\documentclass [MS] {uclathes}

\input {preamble}                         % personal LaTeX macros

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Usually things live in separate flies.
%
% \input {prelim}                           % preliminary page info

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                      %
%                          PRELIMINARY PAGES                           %
%                                                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title          {Diverse R-PPG: Contactless Smartphone Camera-based Heart \\
                Rate Estimation for Diverse Skin Tones and Scenes}
\author         {Krish Kabra}
\department     {Electrical and Computer Engineering}
% Note:  degreeyear should be optional, but as of  5-Feb-96
% it seems required or you get a year of ``2''.   -johnh
\degreeyear     {2021}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chair          {Achuta Kadambi}
\member         {Aydogan Ozcan}
\member         {Mani B. Srivastava}
\member         {Laleh Jalilian}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\dedication     {\textsl{To Mum and Dad. \\
		Your love and support are the root \\
		of my accomplishments.}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\acknowledgments {
This thesis and the research work contained within it was developed during one of humanity's most extraordinary, tragic and enlightening years. The COVID-19 pandemic and rise of the Black Lives Matter movement clearly shaped the initial impetus of the presented research. Therefore, I would first like to acknowledge and give thanks to the healthcare and essential workers who helped us survive this global crisis, and the minority groups who have been and are still being persecuted yet are fighting for a brighter, more fair, and more just future. 

Next, I would like to acknowledge and give thanks to my research advisor, Prof. Achuta Kadambi. Without his guidance, mentorship and support, this work would not have been possible. I am grateful for his technical suggestions, insightful conversations and kind camaraderie, albeit mostly through Zoom. He has ultimately shaped my research ambitions and future career endeavours, and I hope to follow in his footsteps as I advance professionally.

I would also like to acknowledge and give thanks Prof. Laleh Jalilian. Without her, there would be no VITAL dataset. Somehow, while being a full-time physician and researcher, she managed to organize volunteers to be apart of this study, provide medical insight into the research work, and support hungry and stressed graduate students with delicious Persian ice cream. 

Furthermore, I must acknowledge and give thanks to Prof. Aydogan Ozcan and Prof. Mani Srivastava for their support of this thesis. I am grateful for their time and help in completing this work.

I would like to acknowledge and give thanks to all my collaborators, especially Pradyumna Chari. Pradyumna is the champion of this work, and I am grateful to have had him alongside me throughout my research experience. His calm attitude and sharp acuity helped me persevere and overcome the technical challenges faced during this work. I have learnt a great deal from him, and I hope we can continue to collaborate together on future projects.

Additionally, I would like to acknowledge and give thanks to all the volunteers of the VITAL dataset. 

Finally, I would like to acknowledge and give thanks to my friends and family. To all the members of the Visual Machines Group, I am grateful for your friendship throughout the pandemic, especially Chinmay Talegaonkar and Siddarth Somasundaram. To my escape room team, Igor Marques Van Der Put, Leah Phillips, and Fredrick Cropp, thank you for making my final quarter a memorable one filled with mini-adventures and good food. To my FIFA adversary, Vitor Tavares, thanks for sitting alongside me to witness Chelsea win a second UEFA Champions League trophy. And last, but not least, a huge thanks to my Mum, Amrita Kabra, my Dad, Manoj Kabra, and my brother, Pratik Kabra. Your love, support and guidance are truly at the root of my accomplishments. Even though you're no longer with us Dad, you have left behind a legacy that extends far and beyond your life. Thank you so much for everything. 
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\previouspublications {
This thesis revises the following publication: 

P. Chari, K. Kabra, D. Karinca, S. Lahiri, D. Srivastava, K. Kulkarni, T. Chen, M. Can-nesson, L. Jalilian, and A. Kadambi, ``Diverse R-PPG: Camera-based heart rate estimation for diverse subject skin-tones and scenes,'' \textit{arXiv preprint arXiv:2010.12769} (2020)~\cite{chari_diverse_2020}.

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \publication    {\textsl{MADHOUS Reference Manual.}
% 	Stanford University, Dean of Student Affairs
% 	(Residential Education Division), 1978.
% 	Technical documentation for the MADHOUS
% 	software system used to assign students to
% 	on-campus housing.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\abstract       {Heart rate (HR) is an essential clinical measure for the assessment of cardiorespiratory instability. The growing telemedicine market opens up the urgent requirement for scalable yet affordable remote HR estimation. Smartphones that use in-built camera modules to measure HR from facial videos offer a more economical solution in comparison to mass deployment of wearable sensors. However, existing computer vision methods that estimate HR from facial videos exhibit biased performance against dark skin tones. This is a major concern, since communities of color are disproportionately affected by both COVID-19 and cardiovascular disease. We identify the origin of this bias and present a novel physics-driven algorithm that boosts performance on darker skin tones in our reported data. We assess the performance of our method through the creation of the first telemedicine-focused remote vital signs dataset, the VITAL dataset. 472 videos ($\sim$944 minutes) of 59 subjects with diverse skin tones are recorded under realistic scene conditions with corresponding vital sign data. Our method reduces errors due to lighting changes, shadows, and specular highlights and imparts unbiased performance gains across skin tones, setting the stage for making non-contact HR sensing technologies a viable reality for patients across skin tones, using just smartphone cameras.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin {document}
\makeintropages

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Ordinarily each chapter (at least) is in a separate file.
%
\input {include/introduction}  
\input {include/theory}  
\input {include/methods}  
\input {include/results}  
\input {include/conclusions}  
\appendix
\input {include/appendix}

  

\bibliographystyle{IEEEtran}
\bibliography{references}    % bibliography references

\end {document}